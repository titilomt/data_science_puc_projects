{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "nlp-class",
      "language": "python",
      "name": "nlp-class"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Aula 1 - CDBD O8_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7c_d3n-ZE2S4",
        "CpfoYKAaE2TM",
        "2NTIYrv2E2Tb",
        "1Q5VxGluE2Tq",
        "wlWiVFncE2Tu",
        "Wv23KoPjE2Vr",
        "IrmQXE3jE2Vt",
        "lQzdlozyE2V3",
        "T7qnHatKE2WA",
        "ArjkfjHhE2WG",
        "1Raq0rzmE2WQ",
        "tlvmmIF8E2Wb",
        "hoWeL_G-E2We",
        "587tz9g-E2Wr",
        "6JSXgTlKE2Wx",
        "y8uiiVyKE2W2",
        "E2uwnIZOE2W7",
        "rv5WvPOdE2XR",
        "LlBxPaX5E2XT",
        "BOTrcV8QE2XU"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5gScmrSE2SB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0cdbc915-3359-44e9-8838-8d04035c756e"
      },
      "source": [
        "!pip install unidecode\n",
        "!pip install wikipedia\n",
        "!pip install spacy\n",
        "!python -m spacy download en\n",
        "!python -m spacy download pt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 18.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 1.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 3.0MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n",
            "Collecting wikipedia\n",
            "  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-cp36-none-any.whl size=11686 sha256=73495f309562b1d686277a9a4a3d058bdff62a42cfbab88599d78b4d1ff64a0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting pt_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2MB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.5-cp36-none-any.whl size=21186282 sha256=8aae278115ad5131d0c4e8d1ea9e5f3020fbefb5a0fb9beb71939bfd6fe3917f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-liq_ve64/wheels/ea/94/74/ec9be8418e9231b471be5dc7e1b45dd670019a376a6b5bc1c0\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt-GgQqeE2SH",
        "colab_type": "text"
      },
      "source": [
        "# Expressões Regulares\n",
        "\n",
        "- O Pacote que permite utilizar ER é <b>re</b>\n",
        "- Existem vários métodos para utilizar expressões regulares em python., alguns deles para <b>buscar</b> padrões são:\n",
        "\n",
        "|   Método   |                                      Descrição                                     |\n",
        "|:----------:|:----------------------------------------------------------------------------------:|\n",
        "| match()    | Determina se a RE combina com o início da string.                                  |\n",
        "| search()   | Varre toda a string, procurando qualquer local onde esta RE tem correspondência.   |\n",
        "| findall()  | Encontra todas as substrings onde a RE corresponde, e as retorna como uma lista.   |\n",
        "| finditer() | Encontra todas as substrings onde a RE corresponde, e as retorna como um iterador. |\n",
        "\n",
        "- Métodos para modificar strings:\n",
        "\n",
        "| Método  | Descrição                                                                                            |\n",
        "|---------|------------------------------------------------------------------------------------------------------|\n",
        "| split() | Divide a string em uma lista, dividindo-a onde quer que haja correspondência com a RE                |\n",
        "| sub()   | Encontra todas as substrings que correspondem com a RE e faz a substituição por uma string diferente |\n",
        "| subn()  |  É o mesmo que o método sub(), mas retorna a nova string e o número de substituições                 |\n",
        "\n",
        "\n",
        "Link: https://docs.python.org/pt-br/3.8/howto/regex.html\n",
        "\n",
        "Agora vamos exemplificar cada um desses métodos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RuY3ajmE2SH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import datetime"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u06mxHTsE2SM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texto = \"Vamos encontrar Padrões nesta string!! \\nAgora é a nossa primeira prática de NLP!! Vamos aprender a procurar padrões!! \\nBelo Horizonte, \"+ str(datetime.datetime.now().date())+\".\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba2kbQcBE2SR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "219b47f8-f32d-48ae-c70e-0fecbfb8c299"
      },
      "source": [
        "print(texto)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vamos encontrar Padrões nesta string!! \n",
            "Agora é a nossa primeira prática de NLP!! Vamos aprender a procurar padrões!! \n",
            "Belo Horizonte, 2020-09-19.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssoK3Vd_E2SV",
        "colab_type": "text"
      },
      "source": [
        "## Match\n",
        "Determina se a RE combina com o início da string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByKonDoCE2SW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "736b3dee-73a8-4ac9-e175-18ebf05135be"
      },
      "source": [
        "re.match(\"Vamos\", texto)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 5), match='Vamos'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTRtigOPE2Sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re.match(\"nesta\", texto)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWgXERIqE2Se",
        "colab_type": "text"
      },
      "source": [
        "é case sensitive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6nAhURVE2Sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re.match(r\"vamos\", texto)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-vfSwKdE2Sj",
        "colab_type": "text"
      },
      "source": [
        "## Search\n",
        "Varre toda a string, procurando qualquer local onde esta RE tem correspondência"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGwwWNFlE2Sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re.search(\"Vamos\", texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpfXeIsXE2Sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re.search(\"encontrar\", texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW85D7HYE2Sr",
        "colab_type": "text"
      },
      "source": [
        "o default é case-sensitive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcm5_FhyE2Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re.search(\"padrões\", texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlzw89bWE2Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re.search(\"Padrões\", texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcwH5pX1E2S0",
        "colab_type": "text"
      },
      "source": [
        "podemos ignorar case-sensitive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3Ol_N-xE2S1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re.search(\"padrões\", texto, re.IGNORECASE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c_d3n-ZE2S4",
        "colab_type": "text"
      },
      "source": [
        "## Findall\n",
        "Encontra todas as substrings onde a RE corresponde, e as retorna como uma lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RL7Pn6sE2S5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa6486f8-3e0c-4a39-db5a-053e44f5c550"
      },
      "source": [
        "re.findall(\"Vamos\", texto)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Vamos', 'Vamos']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwkAevIaE2S9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fa559fb-aff2-4b1a-a523-803c603c9dc9"
      },
      "source": [
        "re.findall(\"padrões\", texto)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['padrões']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-jU3fAQE2TA",
        "colab_type": "text"
      },
      "source": [
        "re.I é igal re.IGNORECASE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwcBrGrxE2TB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4773f4e-e8df-4e1a-c29f-68d998421019"
      },
      "source": [
        "re.findall(\"padrões\", texto, re.I)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Padrões', 'padrões']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxS4PHcpE2TF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebd73ff1-ca17-40a0-b0ff-eb6487c54e05"
      },
      "source": [
        "#quando uso o + o padrão é 1 ou mais. Assim todas string que tem a no meio de outras letras  são retornadas\n",
        "re.findall(r'\\w+a\\w+', texto)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Vamos', 'encontrar', 'Padrões', 'Vamos', 'procurar', 'padrões']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy1DWTFCE2TJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "5d877dd1-9fd8-4171-8f9a-484123fac986"
      },
      "source": [
        "#quando uso o * o padrão é 0 ou mais. Assim todas string que tem a no meio, ou no início ou no fim são retornadas\n",
        "re.findall(r'\\w*a\\w*', texto)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Vamos',\n",
              " 'encontrar',\n",
              " 'Padrões',\n",
              " 'nesta',\n",
              " 'Agora',\n",
              " 'a',\n",
              " 'nossa',\n",
              " 'primeira',\n",
              " 'prática',\n",
              " 'Vamos',\n",
              " 'aprender',\n",
              " 'a',\n",
              " 'procurar',\n",
              " 'padrões']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpfoYKAaE2TM",
        "colab_type": "text"
      },
      "source": [
        "## Finditer\n",
        "Encontra todas as substrings onde a RE corresponde, e as retorna como um iterador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Npmyb-XsE2TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re.finditer(\"Vamos\", texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BzmQAsvE2TQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = re.finditer(\"Vamos\", texto)\n",
        "[r for r in res]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul95OtbkE2TT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re.finditer(\"padrões\", texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MWvOPBNE2TX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re.finditer(\"padrões\", texto, re.I)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NTIYrv2E2Tb",
        "colab_type": "text"
      },
      "source": [
        "## Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs7VXjcKE2Tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re.split('\\n',texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7moeTtMWE2Tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texto.split(\"\\s+\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjv2o5TSE2Tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(re.split(r'\\s+',texto))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q5VxGluE2Tq",
        "colab_type": "text"
      },
      "source": [
        "## Sub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfQcny0cE2Tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re.sub('\\w+a\\w+', 'a-word', texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlWiVFncE2Tu",
        "colab_type": "text"
      },
      "source": [
        "## Subn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2955Lc9E2Tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "re.subn('\\w+a\\w+', 'a-word', texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nQT6mCwE2T4",
        "colab_type": "text"
      },
      "source": [
        "# Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4o97T52E2T5",
        "colab_type": "text"
      },
      "source": [
        "1. Escreva uma expressão regular para verificar se uma string contém apenas um determinado conjunto de caracteres (neste caso, a-z, A-Z e 0-9)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djXPdCENE2T5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string1 = \"ABCDEFabcdef123450\"\n",
        "string2 = \"*&%@#!}{\""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RREg_VDTE2T9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "518caca7-3625-4538-c67d-aa8256fa6f39"
      },
      "source": [
        "print(re.match(r'^\\w+$', string1))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<_sre.SRE_Match object; span=(0, 18), match='ABCDEFabcdef123450'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpQZWR75E2UB",
        "colab_type": "text"
      },
      "source": [
        "2. Escreva uma expressão regular que corresponda a uma sequência que tenha um a seguido por zero ou mais b's."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clu3aaOQE2UB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string1 = \"abc\"\n",
        "string2 = \"aacb\"\n",
        "string3 = \"abbc\"\n",
        "string4 = \"bb\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDkahkQpE2UE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCEwqVNEE2UJ",
        "colab_type": "text"
      },
      "source": [
        "3. Escreva um expressão regular que corresponda a uma sequência que tenha um a seguido por um ou mais b's."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLIBnksTE2UK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string1 = \"abc\"\n",
        "string2 = \"aacb\"\n",
        "string3 = \"abbc\"\n",
        "string4 = \"bb\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmzRqypfE2UO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNE6awcvE2US",
        "colab_type": "text"
      },
      "source": [
        "4. Escreva uma expressão regular para converter uma data do formato aaaa-mm-dd para o formato dd-mm-aaaa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3-uuyaNE2US",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1 = \"2026-01-02\"\n",
        "data2 = \"26-01-02\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj6O5YplE2UW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-ipfjt3E2Ub",
        "colab_type": "text"
      },
      "source": [
        "5. Escreva uma expressão para remover o excesso de espaço"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS0_qEuME2Uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string = \"Exercídios     Expressão    Regular\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjfvI0gWE2Uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0Hmo0vgE2Uj",
        "colab_type": "text"
      },
      "source": [
        "6. Escreva uma expressão para dividir uma string em letras maiúsculas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODUJ9cftE2Uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string = \"ExercídiosExpressãoRegularAA\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMJUMezGE2Up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhDy3v6dE2Us",
        "colab_type": "text"
      },
      "source": [
        "7. Escreva uma expressão regular para remover a área de parênteses em uma string\n",
        "\n",
        "\n",
        "- Amostra de Entrada: \n",
        "> * [\"example (.br)\", \"w3resource\", \"github (.com)\", \"stackoverflow (.com)\"] </br>\n",
        "* Saída Esperada: \n",
        "> * example\n",
        "> * w3resource\n",
        "> * github\n",
        "> * stackoverflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPYMid0HE2Ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strings = [\"example (.br)\", \"w3resource\", \"github (.com)\", \"stackoverflow (.??)\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAcZMsWyE2Uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "806dfF6gE2U4",
        "colab_type": "text"
      },
      "source": [
        "8. Escreva um programa para quebrar um texto em sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJrjbSJZE2U5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string = \"Vamos encontrar Padrões nesta string!! Agora é a nossa primeira prática de NLP!! Vamos aprender a procurar padrões!! Belo Horizonte 2020.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gURnxE_hE2U_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCmVDDmaE2VC",
        "colab_type": "text"
      },
      "source": [
        "9. Escreva um código para remover os zeros iniciais do IP 216.08.094.196"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFWwhn1gE2VD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ip = \"216.08.094.196\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfZkpPi8E2VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjxxTNmyE2VI",
        "colab_type": "text"
      },
      "source": [
        "10. Recupere todos os \"Twitter\" do arquivo http://humanstxt.org/humans.txt\n",
        "\n",
        "Exemplo de como recuperar o texto dete arquivo web:\n",
        "\n",
        "```python\n",
        "import requests\n",
        "response = requests.get('http://humanstxt.org/humans.txt')\n",
        "print(response.text)\n",
        "```\n",
        "\n",
        "Imprima a quantidade de twitters e todos twitters encontrados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uYm4GRRE2VJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sYrkoReE2VL",
        "colab_type": "text"
      },
      "source": [
        "# Técnicas de Pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXbwa_tqE2VM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "9ee3dd50-9f45-4ccf-bc9e-bad9b246bd26"
      },
      "source": [
        "import nltk\n",
        "import wikipedia\n",
        "import re\n",
        "import spacy\n",
        "from nltk.probability import FreqDist\n",
        "import pt_core_news_sm\n",
        "import en_core_web_sm\n",
        "nltk.download()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> 1\n",
            "Command '1' unrecognized\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> \n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9cCsfqcE2VP",
        "colab_type": "text"
      },
      "source": [
        "## Definindo o corpus\n",
        "\n",
        "Primeiramente, definimos o corpus que iremos trabalhar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EK3o5NME2VQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Caso o pacote wikipedia não funcione:\n",
        "## Entre no link e faça downaload do arquivo https://drive.google.com/open?id=15R1jcugeM5SoGSPIPyG_6X6F3oMlxSBt\n",
        "## Depois leia com o comando abaixo\n",
        "#file = open(\"pln_wikipedia.txt\", 'r')\n",
        "#file_wiki = file.readlines()\n",
        "#file.close()\n",
        "#corpus = '\\n'.join(file_wiki)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm1Ar8uGE2VW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wikipedia.set_lang(\"pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d-E-QsJE2VZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pln = wikipedia.page(\"PLN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGXLthsFE2Vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = pln.content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfjF9QFbE2Vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"O texto que estamos utilizando é da URL\",pln.url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdzdUIqAE2Vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(pln.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv23KoPjE2Vr",
        "colab_type": "text"
      },
      "source": [
        "## Tokenização\n",
        "\n",
        "Existem várias formas de realizar tokenização. \n",
        "1. Split()\n",
        "2. Regex\n",
        "3. NLTK\n",
        "4. ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrmQXE3jE2Vt",
        "colab_type": "text"
      },
      "source": [
        "### Split\n",
        "\n",
        "Faça utilizando o método abaixo\n",
        "<b> Não esqueça de armazenar o resultado na variável abaixo. </b>\n",
        "\n",
        "```python\n",
        "str.split()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5wYhcXRE2Vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_split = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bdDnMyGE2Vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#problema do split é que ele não separa as pontuações.\n",
        "print(tokens_split)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQzdlozyE2V3",
        "colab_type": "text"
      },
      "source": [
        "### Regex\n",
        "\n",
        "Faça utilizando o método abaixo\n",
        "<b> Não esqueça de armazenar o resultado na variável abaixo. </b>\n",
        "\n",
        "```python\n",
        "re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", corpus)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdDQfjLIE2V4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_regex = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IYoOF3bE2V9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Regex\n",
        "print(tokens_regex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7qnHatKE2WA",
        "colab_type": "text"
      },
      "source": [
        "### NLTK\n",
        "\n",
        "Faça utilizando o método abaixo.\n",
        "<b> Não esqueça de armazenar o resultado na variável abaixo. </b>\n",
        "\n",
        "```python\n",
        "nltk.word_tokenize(corpus)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UNG87TUE2WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_nltk = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG26NMKvE2WC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NLTK\n",
        "print(tokens_nltk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko5hVUu8E2WE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_frequencia_tokens(tokens):\n",
        "    fd_words = FreqDist(tokens)\n",
        "    fd_words.plot(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArjkfjHhE2WG",
        "colab_type": "text"
      },
      "source": [
        "### Plot das tokenizações\n",
        "\n",
        "Plote o resultado de cada uma das tokenizações. \n",
        "Utilize o método <b> plot_frequencia_tokens() </b> para plotar o gráfico.\n",
        "Também imprima o tamanho de cada tokenização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVQAm8qEE2WG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Tokens Split\")\n",
        "#faça aqui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eni4lQFkE2WI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Tokens Regex\")\n",
        "#faça aqui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4xA7gAcE2WL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Tokens NLTK\")\n",
        "#faça aqui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DfR9nAtE2WN",
        "colab_type": "text"
      },
      "source": [
        "Como foi possível observar, existem variações nas tokenizações realizadas. \n",
        "A que gerou mais tokens foi a que utilizou regex.\n",
        "Por isso iremos utilizá-la a partir deste ponto.\n",
        "Utilize o resultado de <b> tokens_regex</b>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bnBwV52E2WN",
        "colab_type": "text"
      },
      "source": [
        "## Capitalização\n",
        "\n",
        "traforme todos os tokens para minúsculo utilizando a função abaixo:\n",
        "\n",
        "```python\n",
        "str.lower()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaO8ilaQE2WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_RynFQNE2WP",
        "colab_type": "text"
      },
      "source": [
        " <b> <span style=\"color:red\"> Lembre de utilizar a VARIÁVEL que contém o resultado da transformação anterior.\n",
        "    Se você acompanhar o nome da variável que já está na célula não tem erro! :) </span> </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Raq0rzmE2WQ",
        "colab_type": "text"
      },
      "source": [
        "## Remoção Stopwords\n",
        "\n",
        "remova todas as stopwords retornadas pelo pacote NLTK da lista de tokens.\n",
        "\n",
        "```python\n",
        "portugues_stops = stopwords.words('portuguese')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "360Waq1HE2WQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xP3XVzhE2WU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "portugues_stops = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO6XRhYQE2WW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imprima as stopwords para você conhecer\n",
        "print(portugues_stops)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxkb0ECME2WZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_sem_stop = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlvmmIF8E2Wb",
        "colab_type": "text"
      },
      "source": [
        "## Remoção Números\n",
        "\n",
        "remova todos os números, utilizando uma regex\n",
        "\n",
        "```python\n",
        "re.sub(__,__,__)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbnRocYGE2Wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_sem_numbers = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoWeL_G-E2We",
        "colab_type": "text"
      },
      "source": [
        "## Remoção Pontuação\n",
        "\n",
        "remova todas as pontruações retornadas pelo pacote string da lista de tokens.\n",
        "\n",
        "```python\n",
        "string.punctuation\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dYZ-eB0E2Wg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phDcEdjiE2Wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string.punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXBcTE6HE2Wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_sem_punction = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFw3RfwXE2Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted(tokens_sem_punction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "587tz9g-E2Wr",
        "colab_type": "text"
      },
      "source": [
        "## Remoção Acentos\n",
        "\n",
        "remova todos os acentos utilizando a função abaixo:\n",
        "\n",
        "```python\n",
        "unidecode(str)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb82BTreE2Ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from unidecode import unidecode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cb1oMd1E2Wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_sem_acentos = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JSXgTlKE2Wx",
        "colab_type": "text"
      },
      "source": [
        "###  Plote a frequência dos tokens sem acentos. Utilize o método plot_frequencia_tokens() para plotar o gráfico. Também imprima o tamanho desta lista. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owaL2wn8E2Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokens_sem_acentos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8uiiVyKE2W2",
        "colab_type": "text"
      },
      "source": [
        "## Stemming\n",
        "\n",
        "Iremos utilizar o stemming da biblioteca NLTK. O algoritmo disponível para este procedimento em portugês é o RSLPStemmer.\n",
        "\n",
        "```python\n",
        "stemmer = nltk.stem.RSLPStemmer()\n",
        "#para cada token:\n",
        "stemmer.stem(token)\n",
        "```\n",
        "\n",
        "Aplique o stemmet em cada elemento da lista de tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejHKSTOhE2W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = nltk.stem.RSLPStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6v3wjVZE2W5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_stemmer = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2uwnIZOE2W7",
        "colab_type": "text"
      },
      "source": [
        "###  Plote a frequência dos tokens após o processo de stemming. Utilize o método plot_frequencia_tokens() para plotar o gráfico. Também imprima o tamanho desta lista. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjhx4JyXE2W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokens_stemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESWvVmslE2W-",
        "colab_type": "text"
      },
      "source": [
        "## Lemmatization\n",
        "a biblitoteca NLTK não possui lematização para português.\n",
        "Mas a scpaCy possui."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EteSUdLWE2W-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#carrega o modelo para português\n",
        "#nlp = spacy.load('pt')\n",
        "nlp = pt_core_news_sm.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4v6tMpXE2XE",
        "colab_type": "text"
      },
      "source": [
        "Você pode executar a <b> lematização </b> com acentos ou sem acentos. Funciona da mesma forma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWInspjdE2XE",
        "colab_type": "text"
      },
      "source": [
        "A primeira etapa para executar a lematização é transformar a lista de tokens para uma string. \n",
        "Utilize a variável de tokens: <b> tokens_sem_punction </b>.\n",
        "\n",
        "Dica: utilize o método join para isto:\n",
        "\n",
        "```python\n",
        "str.join(list)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfLEPu_4E2XF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str_tokens = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qprZRw5rE2XH",
        "colab_type": "text"
      },
      "source": [
        "Depois carregue a string de tokens (<b>str_tokens</b>) no modelo <b> nlp </b>, carregado em um dos passos anteriores.\n",
        "\n",
        "```python\n",
        "doc = nlp(str_tokens)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvkUDdatE2XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(str_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EryUAZ-E2XJ",
        "colab_type": "text"
      },
      "source": [
        "Verifique o tipo da variável <b> doc </b>.\n",
        "Observe que é do tipo spacy.tokens.doc.Doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uc-mP5uE2XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNwRqjPXE2XM",
        "colab_type": "text"
      },
      "source": [
        "Como tipo da variável doc é do tipo spacy.tokens.doc.Doc.\n",
        "Apenas é preciso iterar em cada token e retornar o atributo <b> lemma_</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOe5nKehE2XN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_lemm = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P78mZ_giE2XP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(token_lemm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv5WvPOdE2XR",
        "colab_type": "text"
      },
      "source": [
        "###  Plote a frequência dos tokens após o processo de lematização. Utilize o método plot_frequencia_tokens() para plotar o gráfico. Também imprima o tamanho desta lista. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u30lz0JhE2XR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#token_lemm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QKv9pFGE2XT",
        "colab_type": "text"
      },
      "source": [
        "# Perguntas?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlBxPaX5E2XT",
        "colab_type": "text"
      },
      "source": [
        "## 1. Quais diferenças você entrou entre os métodos de tokenização. Cite ao menos 3 tokens com resultados diferentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eZfsGAnE2XU",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOTrcV8QE2XU",
        "colab_type": "text"
      },
      "source": [
        "## 2. Qual a principal diferença que você verificou entre o processo de stemming e de lematização?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbnNTA-HE2XV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
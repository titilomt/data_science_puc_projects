{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Aula 3 - CDDB 8_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a4e3c6e97d33497dafc6ea6f95939952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da1a879a0880442d8691b873096a268b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dddce822f7d24dcd9f378162c557621b",
              "IPY_MODEL_abdb244a287d4f65ad85ce1504237760"
            ]
          }
        },
        "da1a879a0880442d8691b873096a268b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dddce822f7d24dcd9f378162c557621b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ab8a74c0ab94e84b253b5b732a06984",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 49459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c650583df5a4c708f4cd795e64dbc97"
          }
        },
        "abdb244a287d4f65ad85ce1504237760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41ff511115974af0bb34e9c11d99c6c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49459/49459 [01:19&lt;00:00, 622.33it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_362bac079ee14398ab781b1b782bff6e"
          }
        },
        "8ab8a74c0ab94e84b253b5b732a06984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c650583df5a4c708f4cd795e64dbc97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41ff511115974af0bb34e9c11d99c6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "362bac079ee14398ab781b1b782bff6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40d878542fea48d49b5082913f4d8fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f4387cfe25744b8e9dd6744caf14bffc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_78297b7f35574c15a0f64327eabc4ad3",
              "IPY_MODEL_7476b16e9ebd4b188f46ebfde86c2332"
            ]
          }
        },
        "f4387cfe25744b8e9dd6744caf14bffc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78297b7f35574c15a0f64327eabc4ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_971442de7b434795bd98a7f014e9644e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 49459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df5f94c6394c4292813b60f01f9d15f4"
          }
        },
        "7476b16e9ebd4b188f46ebfde86c2332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_559c89ab5fcd498688b0bb8aa107fe7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49459/49459 [00:38&lt;00:00, 1292.61it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53e839a9710e4a858c988519089eee2f"
          }
        },
        "971442de7b434795bd98a7f014e9644e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df5f94c6394c4292813b60f01f9d15f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "559c89ab5fcd498688b0bb8aa107fe7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53e839a9710e4a858c988519089eee2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26b6a29f406243c482e8f06c91163205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d21de2083d545699335b192249fa939",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab157d475f09496b99207c5ba763a9f5",
              "IPY_MODEL_a0b9cc66ef314e8db0d9812698c88f25"
            ]
          }
        },
        "9d21de2083d545699335b192249fa939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab157d475f09496b99207c5ba763a9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7455802d1d434bdc8785fd89ede93e4a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 49459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ba5e89cb6ff4282bdd3987cadad6983"
          }
        },
        "a0b9cc66ef314e8db0d9812698c88f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a0492d9cc1949259b6af0d0e183842f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49459/49459 [02:33&lt;00:00, 323.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3acb0f644bd48c781e4221b0a63e8ad"
          }
        },
        "7455802d1d434bdc8785fd89ede93e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ba5e89cb6ff4282bdd3987cadad6983": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a0492d9cc1949259b6af0d0e183842f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3acb0f644bd48c781e4221b0a63e8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Mgum7LZZmf",
        "outputId": "3b92be94-fd61-4c7e-c1ed-4ddcdfdef45b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "!pip install afinn\n",
        "!python -m textblob.download_corpora\n",
        "!pip install -U textblob\n",
        "!pip install vaderSentiment\n",
        "!pip install pyemd\n",
        "!pip install Unidecode"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: afinn in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n",
            "Requirement already up-to-date: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.6/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2020.6.20)\n",
            "Requirement already satisfied: pyemd in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pyemd) (1.18.5)\n",
            "Collecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR9dcTSYZZml",
        "outputId": "435aa7a8-917c-48fb-e6e2-78299de3168f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "from unidecode import unidecode\n",
        "import pandas as pd\n",
        "import bz2\n",
        "import gensim\n",
        "import warnings\n",
        "import numpy as np\n",
        "from gensim.models import word2vec\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.spatial import distance\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "tqdm_notebook.pandas()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjOYV0cfZZmq"
      },
      "source": [
        "# Carregando os embeddings\n",
        "\n",
        "Aqui vamos utilizar os embeddings para realizar as seguintes atividades:\n",
        "\n",
        "- análise de simlaridade\n",
        "- classificação de documentos\n",
        "\n",
        "<b> Carregue os embeddings treinados, como vimos na Aula 2. É o mesmo arquivo que iremos utilizar</b>\n",
        "\n",
        "Link: https://drive.google.com/open?id=1zI8pGfbUHuU_0wY_FV4tD6w6ZCUJTQbh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqMDMgrBZZmr"
      },
      "source": [
        "newfilepath = \"embedding_wiki_100d_pt.txt\"\n",
        "filepath = \"/tmp/ptwiki_20180420_100d.txt.bz2\"\n",
        "with open(newfilepath, 'wb') as new_file, bz2.BZ2File(filepath, 'rb') as file:\n",
        "    for data in iter(lambda : file.read(100 * 1024), b''):\n",
        "        new_file.write(data)\n",
        "\n",
        "#carregar\n",
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(newfilepath, binary=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqZJuktuZZmv"
      },
      "source": [
        "# Similaridade de Documentos\n",
        "\n",
        "Para realizar a similaridade entre documentos, utilize as frases abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-YjfkcTZZmw"
      },
      "source": [
        "frase1 = \"Excelente produto chegou antes do prazo indico e recomendo produto bom pois já testei e foi mais que aprovado\" \n",
        "frase2 = \"SUPER RECOMENDO, PREÇO, QUALIDADE #BRASTEMP, EFICIÊNCIA NA ENTREGA, E FACILIDADE DE PAGAMENTO. MUITO BOM!!!\"\n",
        "frase3 = \"A tampa do fogão veio com problemas com o pino de encaixe solto e precisa de reparos\"\n",
        "frase4 = \"Fogão ótimo!\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNGfjS5RZZm1"
      },
      "source": [
        "## Distância de Jaccard\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "1) Faça um método que calcule a similaridade de Jaccard e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n",
        "\n",
        "Observação: lembrando que você precisa aplicar um pre-processamento nessas frases antes de aplicar o método.\n",
        "Faça:\n",
        "\n",
        "- Lower\n",
        "- Remoção StopWords\n",
        "- Remoção Pontuação\n",
        "- Tokenização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn2YYL7bZZm2",
        "outputId": "a72cb3dd-405c-4b9e-84f0-d69d2386ccf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def pre_processamento_texto(corpus):\n",
        "    corpus_alt  = re.findall(r\"\\w+(?:'\\w+')?|[^\\w\\s]\",corpus)\n",
        "    corpus_alt  = [t.lower() for t in corpus_alt] \n",
        "    lista_stops = stopwords.words(\"portuguese\")\n",
        "    corpus_alt  = [token for token in corpus_alt if token not in lista_stops]\n",
        "    corpus_alt  = [re.sub(r\"\\d\",\"\", token) for token in corpus_alt]\n",
        "    corpus_alt  = [token for token in corpus_alt if token not in string.punctuation]\n",
        "    corpus_alt  = [unidecode(token) for token in corpus_alt]\n",
        "    return corpus_alt\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['excelente', 'produto', 'chegou', 'antes', 'prazo', 'indico', 'recomendo', 'produto', 'bom', 'pois', 'testei', 'aprovado']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kws6GdxVy0P"
      },
      "source": [
        "###\n",
        "# Pre_processamento de palavras das frases, removendo stopwords e acentos, pontuações\n",
        "# e retorna tokens em minusculo\n",
        "###\n",
        "\n",
        "frase1_pre = pre_processamento_texto(frase1)\n",
        "frase2_pre = pre_processamento_texto(frase2)\n",
        "frase3_pre = pre_processamento_texto(frase3)\n",
        "frase4_pre = pre_processamento_texto(frase4)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZJrrzMWWgYR",
        "outputId": "92df3fd2-5b95-4eb5-8ebc-9785075dbc2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Jaccard = Intercessão / União\n",
        "\n",
        "def jaccard_method(f1, f2): \n",
        "    return len(set(f1).intersection(set(f2)))/len(set(f1).union(set(f2)))\n",
        "\n",
        "# Frase1 e Frase2\n",
        "# Frase1 e Frase3\n",
        "# Frase2 e Frase3\n",
        "# Frase1 e Frase4\n",
        "print(jaccard_method(frase1_pre, frase2_pre))\n",
        "print(jaccard_method(frase1_pre, frase3_pre))\n",
        "print(jaccard_method(frase2_pre, frase3_pre))\n",
        "print(jaccard_method(frase1_pre, frase4_pre))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.10526315789473684\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke1PVggcZZm8"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "2) Qual par de frase teve maior simlaridade? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g7wRRl_ZZm9"
      },
      "source": [
        "O par frase1 e frase2 possuí maior similaridade por conter dentro de seus tokens (palavras) semelhanças de uma com a outra, o que não ocorre com as demais palavras. Portanto, este resultado faz sentindo uma vez que a intercessão de palavras distintas é 0 entre as demais frases testadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND3usAELZZm-"
      },
      "source": [
        "## Distância de Cosseno\n",
        "\n",
        "Aqui iremos calcular a distância do cosseno utilizando duas formas, que aprendemos na aula passada, para representar o texto.\n",
        "\n",
        "- Bag of Words (BOW) \n",
        "- Embedding\n",
        "\n",
        "Observação:\n",
        "\n",
        "Existem duas formas de trabalhar com o cosseno:\n",
        "\n",
        "<b> Distância </b>: quanto menor mais perto estão as frases.\n",
        "<b> Similaridade </b>: quanto maior mais perto estão as frases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Qw93ZLZZm-"
      },
      "source": [
        "### BOW - Distância do cosseno\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "3) Calcule a distância do cosseno utilizando a representação CountVectorizer e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n",
        "\n",
        "Observação: no CountVectorizer utilizem as frases já pre-processadas da atividade anterior. Mas para aplicá-las no fit_transform, cada frase deve ser um string (sem estar tokenizada) dentro de uma lista.\n",
        "\n",
        "```python\n",
        "#exemplo\n",
        "distance.cosine(frase1, frase2)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CzqpPPGZZm_"
      },
      "source": [
        "bow = CountVectorizer()\n",
        "\n",
        "vector = bow.fit_transform([' '.join(frase1_pre), \n",
        "                            ' '.join(frase2_pre),\n",
        "                            ' '.join(frase3_pre),\n",
        "                            ' '.join(frase4_pre)])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RsTI3KRak69",
        "outputId": "8f1e809b-d7f8-4329-b066-6d7c2c6206b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vector.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHh3dHRMa3Xj",
        "outputId": "e7252c84-2fad-4b33-8ccb-49eda29298e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "pd.DataFrame(vector.todense())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0   1   2   3   4   5   6   7   8   ...  20  21  22  23  24  25  26  27  28\n",
              "0   1   1   1   0   1   0   0   0   1  ...   2   0   1   0   0   0   0   1   0\n",
              "1   0   0   1   1   0   1   0   1   0  ...   0   1   1   0   0   1   0   0   0\n",
              "2   0   0   0   0   0   0   1   0   0  ...   0   0   0   1   1   0   1   0   1\n",
              "3   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "\n",
              "[4 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IctZjSGYd5CU"
      },
      "source": [
        "frase1_bow = vector.todense()[0]\n",
        "frase2_bow = vector.todense()[1]\n",
        "frase3_bow = vector.todense()[2]\n",
        "frase4_bow = vector.todense()[3]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZoOGjaAd-I5",
        "outputId": "561bf0bd-37a3-4f77-ed9e-4f58cdcbc841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(distance.cosine(frase1_bow,frase2_bow))\n",
        "print(distance.cosine(frase1_bow,frase3_bow))\n",
        "print(distance.cosine(frase2_bow,frase3_bow))\n",
        "print(distance.cosine(frase1_bow,frase4_bow))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8309691490542968\n",
            "1.0\n",
            "1.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcFS1MKzZZnE"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "\n",
        "4) Qual par de frase teve maior distância? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buNHHZPgZZnF"
      },
      "source": [
        "As frases f1 - f3, f1 - f4, f2 - f3, tiveram resultados cosseno iguais a 1.0, o que nos mostra que sua similaridade é nula, podemos ver que ao abrir estas frases, as palavras usadas, são distintas. A menor distância cosseno foi da frase1 e frase2, exatamente como esperado, pois estas frases tem palavras em comum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3G4ckzlZZnN"
      },
      "source": [
        "### Embedding - Distância do cosseno\n",
        "\n",
        "Para calcular o embedding de cada uma das frases, utilize o modelo carregado inicialmente. \n",
        "\n",
        "Cada palavra tem um vetor, para formar o embedding da frase tire a média de todos os vetores.\n",
        "\n",
        "Utilize as frases já pre-processadas\n",
        "\n",
        "<b> Atividade </b> \n",
        "\n",
        "5) Calcule a distância do cosseno utilizando a representação Embedding e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRO8RnLgZZnO",
        "outputId": "a0cec997-1e37-4f87-ce87-42324b7834f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean(np.array([word_vectors[palavra] for palavra in frase1_pre]), axis=0).shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns8jgP8DfoBk",
        "outputId": "2363863e-061b-473a-f7f2-a31141913bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "word_vectors[\"testei\"]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.7639,  0.3701, -0.8806, -0.2736, -1.1103,  0.4136,  0.147 ,\n",
              "        0.6423, -0.1022,  0.5495, -0.1379,  0.8172, -0.4062,  0.0082,\n",
              "       -0.3987,  0.6067,  0.5797, -0.3458, -0.3474, -0.3411, -0.2711,\n",
              "        0.3904, -0.466 ,  0.1123, -0.0695, -0.1692, -0.3848, -0.4922,\n",
              "       -0.7122,  0.402 ,  0.2955, -0.5608,  0.976 ,  0.5732, -0.0393,\n",
              "       -0.0741,  0.4224,  0.319 ,  0.5793, -0.2527,  0.5185, -0.2147,\n",
              "       -0.3736, -0.5574,  0.3233, -0.1902, -0.6013, -0.0891, -1.021 ,\n",
              "        0.777 ,  0.3467,  0.046 ,  0.2413, -0.4255,  0.4669, -0.1585,\n",
              "       -0.3398,  0.3088, -0.0472,  0.4295,  0.9259, -0.0159, -0.3963,\n",
              "        0.1668,  0.0899, -0.0103,  0.1233,  0.9663, -0.3848,  0.3967,\n",
              "       -0.5887,  0.8346,  0.2106, -0.6855, -0.0744, -0.4362, -0.8564,\n",
              "        0.2475,  0.1882,  0.1293, -0.3085, -0.6424, -0.9031, -0.1352,\n",
              "       -0.3293,  0.5941, -0.0351, -0.0781,  0.5484,  0.7644,  0.3971,\n",
              "        0.0968,  0.2734,  0.3265,  0.2035,  0.2835,  0.173 , -0.3811,\n",
              "       -0.1333, -0.2788], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdCIu5zQf57a",
        "outputId": "fcf5375e-d53b-41f0-8662-e596976c217a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array([word_vectors[palavra] for palavra in frase1_pre]).shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8JzSLlJfxWu"
      },
      "source": [
        "def get_embedding(f):\n",
        "    return np.mean(np.array([word_vectors[palavra] for palavra in f if palavra in word_vectors.vocab]), axis=0)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TEm5Q3-gD29"
      },
      "source": [
        "frase1_emb = get_embedding(frase1_pre)\n",
        "frase2_emb = get_embedding(frase2_pre)\n",
        "frase3_emb = get_embedding(frase3_pre)\n",
        "frase4_emb = get_embedding(frase4_pre)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2a5J1_dgM8B",
        "outputId": "d693a6d9-b851-4857-bff1-d9845cb94a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(distance.cosine(frase1_emb,frase2_emb))\n",
        "print(distance.cosine(frase1_emb,frase3_emb))\n",
        "print(distance.cosine(frase2_emb,frase3_emb))\n",
        "print(distance.cosine(frase1_emb,frase4_emb))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.15136468410491943\n",
            "0.21427351236343384\n",
            "0.24302351474761963\n",
            "0.32684141397476196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgZWHiGSZZnT"
      },
      "source": [
        "<b>Atividade </b>\n",
        "\n",
        "6) Qual par de frase teve maior distância? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsFFxOoeZZnU"
      },
      "source": [
        "O resultado foi similar ao apresentado na questão anterior, as maiores distâncias foram das frases que nada tem em comum e a frase 1 e frase 2, que possuem suas similaridades, tiveram uma distância mais considerável. Vale lembrar que após aplicar o embedding as palavras pré-processadas, ganharam um peso extra que pode explicar alguns valores próximos de 0.20 que representaria um certo grau de similaridade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx5acLVhZZne"
      },
      "source": [
        "## WMD\n",
        "\n",
        "O WMD já está incorporado ao Word2Vec\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "7) Calcule a distância WMD e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n",
        "\n",
        "Observação: use a variável já tokenizada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0881q7vZZne",
        "outputId": "059a264c-57ed-470b-e04f-f43d2452c06c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Frase 1 e 2 \",word_vectors.wmdistance(frase1_pre, frase2_pre))\n",
        "print(\"Frase 1 e 3 \",word_vectors.wmdistance(frase1_pre, frase3_pre))\n",
        "print(\"Frase 2 e 3 \",word_vectors.wmdistance(frase2_pre, frase3_pre))\n",
        "print(\"Frase 1 e 4 \",word_vectors.wmdistance(frase1_pre, frase4_pre))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frase 1 e 2  3.0444450580164455\n",
            "Frase 1 e 3  3.715277379918346\n",
            "Frase 2 e 3  3.7981251887017256\n",
            "Frase 1 e 4  4.125106107605237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsIENn25ZZni"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "8) Qual par de frase teve maior distância? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhC4OvGWZZnj"
      },
      "source": [
        "Novamente, temos os valores se repetindo onde a frase com maior similaridade possui um valor menor de WMD que quanto maior seu índice maior é seu nível de dessimilaridade ou desigualdade entre as frases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXHGivtDZZnk"
      },
      "source": [
        "# Classificação de Documentos\n",
        "\n",
        "A clssificação de documentos é muito útil em vários aspectos. Um dos tipos de classificação de texto é a análise de sentimentos.\n",
        "\n",
        "A fim de ilustrar a classificação de documentos iremos criar um modelo para classificar uma frase como positiva ou negativa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhCOoEn7ZZno"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "9) Carregue o dataset com o pandas e depois dê o head no dataframe.\n",
        "\n",
        "\n",
        "Link download: https://drive.google.com/open?id=15azJWdEEPGsXQGiDmEOseTBJcquWvBQc\n",
        "\n",
        "<b> Este dataset é sobre revisões de filmes do IMDB. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI0oXiOoZZnp"
      },
      "source": [
        "df = pd.read_csv(\"/tmp/imdb-reviews-pt-br.csv\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJYAOZecZZnv",
        "outputId": "0a6e4383-7d3b-491a-ba6b-72d38283b4d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df[\"sentiment\"].value_counts()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neg    24765\n",
              "pos    24694\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCKr5KPMZZnz"
      },
      "source": [
        "## Representação dos dados\n",
        "\n",
        "O sentimento positivo e negativo iremos binarizar cada um deles. Seja 1 positivo e 0 negativo.\n",
        "\n",
        "Iremos representar o texto de duas formas:\n",
        "\n",
        "- Bag of Words (BOW)\n",
        "- Embedding\n",
        "\n",
        "Depois iremos comparar o resultado de cada um deles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkSAiYMZZn0"
      },
      "source": [
        "### Representação Target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0mYbWgcZZn1"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "10) Faça a representação dos sentimentos. 1 positivo; 0 negativo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBkDjo4VZZn2"
      },
      "source": [
        "target = df[\"sentiment\"].replace([\"neg\",\"pos\"],[0,1])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jD5OChwpEtI",
        "outputId": "ccf8c7a8-f3d5-46a4-a73c-fcf8faa7bd3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49459,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8VgGgUnZZn8"
      },
      "source": [
        "### Bag of Words (BOW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xirBWWCzZZn-"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "11) Aplique o pré-processamento listado abaixo na coluna ``text_pt`` (crie uma nova coluna ```text_pt_sem_stopwords``` no dataframe para armazenar este dado processado):\n",
        "\n",
        "- Remova as stopwords do texto\n",
        "- Remova as pontuções\n",
        "- Mantenha o texto sem tokenização, ou seja uma string\n",
        "\n",
        "<b> Dica: </b> use o ```progress_apply``` para exibir a barra de progresso:\n",
        "\n",
        "```python\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "df[\"colunas\"].progress_apply(lambda x: preprocessamento(x))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHLMsY9WpSC5"
      },
      "source": [
        "def pre_processamento_texto_return_str(corpus):\n",
        "    \n",
        "    corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\",corpus)\n",
        "    \n",
        "    lista_stopwords = stopwords.words(\"portuguese\")\n",
        "    corpus_alt = [t for t in corpus_alt if t not in lista_stopwords]\n",
        "    corpus_alt = [t for t in corpus_alt if t not in string.punctuation]\n",
        "    \n",
        "    corpus_alt = [re.sub(r'\\d', '', t) for t in corpus_alt]\n",
        "    \n",
        "    corpus_alt_str = ' '.join(corpus_alt)\n",
        "    \n",
        "    return corpus_alt_str.lower()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnJokm8VZZn-",
        "outputId": "0b204200-4331-4a67-e5d2-a7ffdeb7ce65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "a4e3c6e97d33497dafc6ea6f95939952",
            "da1a879a0880442d8691b873096a268b",
            "dddce822f7d24dcd9f378162c557621b",
            "abdb244a287d4f65ad85ce1504237760",
            "8ab8a74c0ab94e84b253b5b732a06984",
            "9c650583df5a4c708f4cd795e64dbc97",
            "41ff511115974af0bb34e9c11d99c6c4",
            "362bac079ee14398ab781b1b782bff6e"
          ]
        }
      },
      "source": [
        "df[\"text_pt_sem_stopwords\"] = df[\"text_pt\"].progress_apply(lambda x: pre_processamento_texto_return_str(x))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4e3c6e97d33497dafc6ea6f95939952",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=49459.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cvh4Hx5pqvT",
        "outputId": "a05f2d91-6e34-4945-b926-58986b055fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text_en</th>\n",
              "      <th>text_pt</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_pt_sem_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
              "      <td>neg</td>\n",
              "      <td>mais vez sr costner arrumou filme tempo necess...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
              "      <td>neg</td>\n",
              "      <td>este exemplo motivo maioria filmes ação mesmos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>primeiro tudo odeio raps imbecis poderiam agir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>nem beatles puderam escrever músicas todos gos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
              "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
              "      <td>neg</td>\n",
              "      <td>filmes fotos latão palavra apropriada verdade ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                              text_pt_sem_stopwords\n",
              "0   1  ...  mais vez sr costner arrumou filme tempo necess...\n",
              "1   2  ...  este exemplo motivo maioria filmes ação mesmos...\n",
              "2   3  ...  primeiro tudo odeio raps imbecis poderiam agir...\n",
              "3   4  ...  nem beatles puderam escrever músicas todos gos...\n",
              "4   5  ...  filmes fotos latão palavra apropriada verdade ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TddT2Y6JZZoC"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "12) Aplique a representação do texto processado anteriormente com CountVectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axSZo69tZZoC"
      },
      "source": [
        "bow = CountVectorizer()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qexsujompyQt"
      },
      "source": [
        "x_bow = bow.fit_transform(df[\"text_pt_sem_stopwords\"])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz6rQ5ptp09b"
      },
      "source": [
        "vetor = bow.fit_transform([' '.join(frase1_pre),\n",
        "                    ' '.join(frase2_pre),\n",
        "                    ' '.join(frase3_pre),\n",
        "                    ' '.join(frase4_pre)])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfDfqt3Mp8or"
      },
      "source": [
        "X_bow = bow.fit_transform(df[\"text_pt_sem_stopwords\"])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCCJdak3p_2j",
        "outputId": "e9591868-d615-48c0-d929-f9853929002b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_bow.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49459, 127624)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mELsQ0tvZZoF"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSUe-Yr_ZZoG"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "13) Aplique o pré-processamento listado abaixo na coluna ``text_pt`` (crie uma nova coluna ```text_pt_sem_stopwords_token``` no dataframe para armazenar este dado processado):\n",
        "\n",
        "- Aplique lower\n",
        "- Remova as stopwords do texto\n",
        "- Remova as pontuções\n",
        "- Mantenha o texto com tokenização\n",
        "\n",
        "<b> Dica: </b> use o ```progress_apply``` para exibir a barra de progresso:\n",
        "\n",
        "```python\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "df[\"colunas\"].progress_apply(lambda x: preprocessamento(x))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBJxB_SsZZoH"
      },
      "source": [
        "def pre_processamento_texto_return_token(corpus):\n",
        "    \n",
        "    corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\",corpus)\n",
        "    \n",
        "    lista_stopwords = stopwords.words(\"portuguese\")\n",
        "    corpus_alt = [t for t in corpus_alt if t not in lista_stopwords]\n",
        "    corpus_alt = [t for t in corpus_alt if t not in string.punctuation]\n",
        "    \n",
        "    corpus_alt = [re.sub(r'\\d', '', t) for t in corpus_alt]\n",
        "    \n",
        "    \n",
        "    return corpus_alt"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqEH_gGaqHL0",
        "outputId": "d790708f-2167-42ea-d402-2317fbcddf70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "40d878542fea48d49b5082913f4d8fc1",
            "f4387cfe25744b8e9dd6744caf14bffc",
            "78297b7f35574c15a0f64327eabc4ad3",
            "7476b16e9ebd4b188f46ebfde86c2332",
            "971442de7b434795bd98a7f014e9644e",
            "df5f94c6394c4292813b60f01f9d15f4",
            "559c89ab5fcd498688b0bb8aa107fe7a",
            "53e839a9710e4a858c988519089eee2f"
          ]
        }
      },
      "source": [
        "df[\"text_pt_sem_stopwords_token\"] = df[\"text_pt\"].progress_apply(lambda x: pre_processamento_texto_return_token(x))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40d878542fea48d49b5082913f4d8fc1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=49459.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YipHX6zVqMfY",
        "outputId": "1e97cef3-bfa3-4f80-883e-5809e5d1fe50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text_en</th>\n",
              "      <th>text_pt</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_pt_sem_stopwords</th>\n",
              "      <th>text_pt_sem_stopwords_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
              "      <td>neg</td>\n",
              "      <td>mais vez sr costner arrumou filme tempo necess...</td>\n",
              "      <td>[Mais, vez, Sr, Costner, arrumou, filme, tempo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
              "      <td>neg</td>\n",
              "      <td>este exemplo motivo maioria filmes ação mesmos...</td>\n",
              "      <td>[Este, exemplo, motivo, maioria, filmes, ação,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>primeiro tudo odeio raps imbecis poderiam agir...</td>\n",
              "      <td>[Primeiro, tudo, odeio, raps, imbecis, poderia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>nem beatles puderam escrever músicas todos gos...</td>\n",
              "      <td>[Nem, Beatles, puderam, escrever, músicas, tod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
              "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
              "      <td>neg</td>\n",
              "      <td>filmes fotos latão palavra apropriada verdade ...</td>\n",
              "      <td>[Filmes, fotos, latão, palavra, apropriada, ve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                        text_pt_sem_stopwords_token\n",
              "0   1  ...  [Mais, vez, Sr, Costner, arrumou, filme, tempo...\n",
              "1   2  ...  [Este, exemplo, motivo, maioria, filmes, ação,...\n",
              "2   3  ...  [Primeiro, tudo, odeio, raps, imbecis, poderia...\n",
              "3   4  ...  [Nem, Beatles, puderam, escrever, músicas, tod...\n",
              "4   5  ...  [Filmes, fotos, latão, palavra, apropriada, ve...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZPhMIrWZZoM"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "14) Aplique a representação do texto com Embeddings. Cada palavra tem um embedding, o embedding da frase é a média de todos embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4gg0S5NZZoM",
        "outputId": "a30e73b1-cbbe-4ef4-ea58-85b79f97a2ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "26b6a29f406243c482e8f06c91163205",
            "9d21de2083d545699335b192249fa939",
            "ab157d475f09496b99207c5ba763a9f5",
            "a0b9cc66ef314e8db0d9812698c88f25",
            "7455802d1d434bdc8785fd89ede93e4a",
            "8ba5e89cb6ff4282bdd3987cadad6983",
            "5a0492d9cc1949259b6af0d0e183842f",
            "d3acb0f644bd48c781e4221b0a63e8ad"
          ]
        }
      },
      "source": [
        "X_embedding = df[\"text_pt_sem_stopwords_token\"].progress_apply(lambda x: get_embedding(x))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26b6a29f406243c482e8f06c91163205",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=49459.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3baiAE77qa5p",
        "outputId": "9ed767a3-208d-4b3c-e08d-6cb84a5e8501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_embedding.head()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [0.1722594, 0.20761016, -0.053872462, -0.22401...\n",
              "1    [0.17371698, 0.187417, -0.064705655, -0.208970...\n",
              "2    [0.23271771, 0.13545005, -0.0045176437, -0.179...\n",
              "3    [0.26263848, 0.13604508, -0.07352549, -0.20097...\n",
              "4    [0.21992578, 0.10650969, -0.09349515, -0.14721...\n",
              "Name: text_pt_sem_stopwords_token, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smuMLA5Aqhnv",
        "outputId": "01c7d344-18de-46b1-b262-d3a034e4dfa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_embedding)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49459"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqPJf0yLZZoQ"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_xhW7e2ZZoQ"
      },
      "source": [
        "### CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpcc167FZZoR"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "15) Faça a divisão dados dados em treino e teste como no exemplo abaixo:\n",
        "\n",
        "```python\n",
        "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bag, target,random_state=123)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3MeGchRZZoS"
      },
      "source": [
        "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bow, target, random_state=123)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kuekl8WqrlW",
        "outputId": "def7bcad-187d-47d0-d3e9-45a689922fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_bow"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<49459x127624 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 5267081 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1--rXvwqtta",
        "outputId": "c8f776d8-29a8-4f17-c292-6213dd0e29f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train_bow"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<37094x127624 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 3944594 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXsZHGmhqvgD",
        "outputId": "dd44b1a6-2c52-4b5d-d664-74a3214df719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_test_bow"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<12365x127624 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1322487 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0ggm8ZLZZoY"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "16) Treine com uma regressão logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJN8KMHiZZoa"
      },
      "source": [
        "modelo = LogisticRegression()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppohJIQSq9TY",
        "outputId": "0e95e19e-8566-46ed-a8f9-f18cf9a0da6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "modelo.fit(X_train_bow, y_train_bow)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivlITfC2ZZof"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "17) Calcule as métricas de resultado utilizando método abaixo:\n",
        "\n",
        "```python\n",
        "print(classification_report(y_test_bow, y_pred))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsfRxqjSZZog",
        "outputId": "2b252405-8de9-4658-f1b1-ca2a01101a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "modelo.predict(X_test_bow)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug7cB5_0rDWU"
      },
      "source": [
        "predicoes = modelo.predict(X_test_bow)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMfevLZarGoP",
        "outputId": "93e64b7d-fe16-4a7a-9deb-90e785aee3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test_bow.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12365,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtgNXONPrLO7",
        "outputId": "15d0b15f-93db-4fe9-f3b6-8a095339ef00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test_bow, predicoes))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.88      6112\n",
            "           1       0.87      0.89      0.88      6253\n",
            "\n",
            "    accuracy                           0.88     12365\n",
            "   macro avg       0.88      0.88      0.88     12365\n",
            "weighted avg       0.88      0.88      0.88     12365\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiulNTGNZZoj"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6abN65iqZZok"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "18) Faça a divisão dados dados em treino e teste como no exemplo abaixo:\n",
        "\n",
        "Verifique o shape do X treino e X teste. Caso eles estejam com apenas uma dimensão, você precisa tranformá-los para duas dimensões, caso contrário ocorrerá erro no treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn57b04_ZZol"
      },
      "source": [
        "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(X_embedding, target, random_state=123)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7ggFhuQrTvt",
        "outputId": "5d6766a7-dac6-48ac-8eae-a92feb82f53e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_train_emb)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37094"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4nY3d0ormEn",
        "outputId": "bddd563a-668f-4e2e-9b38-8b21693bc5f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(y_train_emb)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37094"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9BR0H7fZZop"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "19) Treine com uma regressão logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJI29fY2ZZoq"
      },
      "source": [
        "modelo_regressao = LogisticRegression()"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNJJKf6ZrrOE",
        "outputId": "4ecdc3b4-88a2-436a-cc9f-08c4fbe87ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_emb.shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37094,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGdTWBuPrtZe"
      },
      "source": [
        "X_train_emb = pd.DataFrame([x for x in X_train_emb])"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdLgXc_wrw1r",
        "outputId": "f96f41cb-2ce1-4078-9de3-493bb66c1236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_emb.shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37094, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNR7_TRcr1AZ"
      },
      "source": [
        "X_test_emb = pd.DataFrame([x for x in X_test_emb])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3sO5Zhwr3kb",
        "outputId": "e40a4e55-a724-4cf1-8cad-5209e3413de5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test_emb.shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12365, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io1HbFySr5yA",
        "outputId": "da20f581-c9bd-4b1f-fb59-09c60b6290cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "modelo.fit(X_train_emb, y_train_emb)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvIYI1lJZZow"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "20) Calcule as métricas de resultado utilizando método abaixo:\n",
        "\n",
        "```python\n",
        "print(classification_report(y_test_bow, y_pred))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClFB32whZZox"
      },
      "source": [
        "#### Calcule as métricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-dRYhR_ZZoy"
      },
      "source": [
        "predicoes = modelo.predict(X_test_emb)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4f6iRglsBIx",
        "outputId": "b876368d-e6e6-48f9-c255-9cf8bb35e2ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test_bow, predicoes))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.78      0.78      6112\n",
            "           1       0.78      0.77      0.78      6253\n",
            "\n",
            "    accuracy                           0.78     12365\n",
            "   macro avg       0.78      0.78      0.78     12365\n",
            "weighted avg       0.78      0.78      0.78     12365\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tqiPbcqsKkM"
      },
      "source": [
        "modelo = modelo.predict(X_test_emb)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r9fF_EpsNOd",
        "outputId": "5834677b-dd93-46bc-bf3e-9b2a31c16ed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test_emb, modelo))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.78      0.78      6112\n",
            "           1       0.78      0.77      0.78      6253\n",
            "\n",
            "    accuracy                           0.78     12365\n",
            "   macro avg       0.78      0.78      0.78     12365\n",
            "weighted avg       0.78      0.78      0.78     12365\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sp62Sb1ZZo1"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "21) Compare os resultados obtidos com o BagOfWords e com o Embedding. Explique os possíveis motivos desta diferença."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RShZ0680ZZo2"
      },
      "source": [
        "A estrutura do BOW permite se criar vetores com a relação de cada palavra e dar um \"peso\" para esta relação, o que pode ser uma explicação para a diferença de acertos entre este modelo e o tipo Embedding, que neste caso apresenta pouca eficiência por, talvez, faltar atributos de especificidade dentro do modelo para que ele possa ser mais acertivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-oH0GQfZZo3"
      },
      "source": [
        "# Análise de sentimentos\n",
        "\n",
        "O modelo que criamos anteriormente é para ilustrar como podemos realizar classificação de documentos.\n",
        "Quando a tarefa é sobre análise de sentimentos, temos duas opções: treinar nosso próprio modelo, como feito anteriormente ou utilizar uma das inúmeras ferramentas prontas.\n",
        "\n",
        "Vamos testar as seguintes ferramentas:\n",
        "\n",
        "- Vader\n",
        "- Textblob\n",
        "- Affin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilpNXE0cZZo3"
      },
      "source": [
        "Nesta atividade iremos utilizar as duas variáveis abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq0dLI9JZZo4"
      },
      "source": [
        "texto_neg = df.loc[0, \"text_en\"]\n",
        "texto_pos = df.loc[49431, \"text_en\"]"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhXGLUM_trGv",
        "outputId": "db56acc1-05fb-48fb-f574-f28e9a656ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "texto_neg"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costners character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks hes better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutchers ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvvn2dCXtsas",
        "outputId": "7b876b56-3311-4d0e-8897-73970a09c0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "texto_pos"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'SPOILERS THROUGH: I really am in the minority on this one but I liked this movie. Its not a classic but its definitely involving and quite an adrenalin fueled ride. I definitely thought it was worth at least a 7 rating.Perhaps the reason I liked it is because I havent seen the original.Something tells me that with a movie like this its strongest fans will be the people who have not seen the original version and thus, have little to compare it to. This was not a masterpiece but I did get into it quite a lot and it actually made me want to see the original.There were a few things I liked about it. One was the casting of Kowalkski. Viggo Mortenson was superb and really brought a lot of charisma to the role. Since the bulk of the movie fell on his shoulders, he really needed to be excellent and he was. This was a great role for him.Another interesting thing about Vansishing Point was the fact that its made for television. I had no idea this was the case when watching it. It sure seemed like a major motion picture and I would never have guessed this was not a big screen release.I also found the story to be very absorbing. Im not one for action movies but I got sucked into this. Plus it was a lot more then an action movie in that there was drama, mysticism, a love story, quirky people every which way you turned. I didnt even recognize Priestly. And it was touching. This was not a great movie but it is watchable.And then theres the ending. It packs a strong punch and if ones been involved in the story up to that point, its very difficult not to be transfixed at the very end. I am not sure how I feel about the ending. The implication was that Kowalkski survived and though Im highly skeptical of HOW that would be possible, it is a movie and realism isnt an ingredient thats always in the mix when making a movie.So Id have to say I found the end incredibly unrealistic but very touching in a manipulative kind of way, which I dont usually like but for some reason, is almost forgivable in this movie. Admittedly, a lot of things were just props for the plotcould the villains have been anymore stereotypical? But the makers got a lot right even if they got many things wrong as well. However, having said that, I will admit I can understand why someone whos a major fan of the original would hate this version because, though I have not seen the original, I have seen many original movies I loved being remade with terrible results. My big dislike is actually sequels. But I can understand the low ratings if the original is of that high a quality.People have compared this to Smoky and the Bandit. How about a road version of \"Legends Of The Fall\" meets \"Thelma and Louese\" as well? I sure felt touches of both filmsboth of which Im a fan of. I do not think however, that this was a great film. It was better then average to me but far from great. But it was an absorbing, adrenalin fueled, touching movie with excellent casting of the main character. My vote is 7 of 10.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dB-FuBgZZo9"
      },
      "source": [
        "## Vader\n",
        "\n",
        "<b> Apenas Inglês </b>\n",
        "\n",
        "O VADER (Valence Aware Dictionary e sEntiment Reasoner) é uma ferramenta de análise de sentimentos baseada em regras e léxico, especificamente identifica os sentimentos expressos nas mídias sociais.\n",
        "\n",
        "- positive sentiment: compound score >= 0.05\n",
        "- neutral sentiment: (compound score > -0.05) e (compound score < 0.05)\n",
        "- negative sentiment: compound score <= -0.05\n",
        "\n",
        "Mais informações: https://github.com/cjhutto/vaderSentiment\n",
        "\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "22) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
        "Para aplicar:\n",
        "\n",
        "```python\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "analyzer.polarity_scores(texto)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZE5KL-9ZZo9"
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzsgloUpZZpB"
      },
      "source": [
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHl2CCjRtzTd",
        "outputId": "2c0af014-5128-427a-cb01-013cf4995679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "analyzer.polarity_scores(texto_neg)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.3958, 'neg': 0.126, 'neu': 0.76, 'pos': 0.114}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL9dwIWyt2FJ",
        "outputId": "b9e4a0a2-7c54-4692-f6fb-26fdd74f9f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "analyzer.polarity_scores(texto_pos)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.9969, 'neg': 0.084, 'neu': 0.737, 'pos': 0.179}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDrJTCfKZZpE"
      },
      "source": [
        "## TextBlob\n",
        "\n",
        "<b> Apenas inglês </b>\n",
        "\n",
        "https://www.presentslide.in/2019/08/sentiment-analysis-textblob-library.html\n",
        "\n",
        "<b> Atividade </b>\n",
        " \n",
        "23) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
        "Para aplicar:\n",
        "\n",
        "```python\n",
        "sentence=TextBlob(texto)\n",
        "sentence.sentiment\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9IvBg5sZZpE"
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-BV6UkOZZpJ",
        "outputId": "5df5a4d1-e23e-4c15-9642-a7b0456c50b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence=TextBlob(texto_neg)\n",
        "sentence.sentiment"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.06385964912280702, subjectivity=0.5629824561403508)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1HyveDUt9Cz",
        "outputId": "384e9cb8-84bd-46d6-e0d9-7171215f5a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence=TextBlob(texto_pos)\n",
        "sentence.sentiment"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.190819118692253, subjectivity=0.6026226012793177)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwk7dHuFZZpO"
      },
      "source": [
        "## Afinn\n",
        "\n",
        "- Valor maior que 0 indica sentimento positivo\n",
        "- Valor menor que 0 indica sentimento negativo\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "24) Aplique este método nas revisões ```texto_pos``` e ```texto_neg```.\n",
        "Para aplicar:\n",
        "\n",
        "```python\n",
        "afinn = Afinn()\n",
        "afinn.score(texto)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2FS5AUsZZpP"
      },
      "source": [
        "from afinn import Afinn"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF8E0CjzZZpX"
      },
      "source": [
        "afinn = Afinn()"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFeaPAlluCUu",
        "outputId": "b396a80d-0798-4762-92a0-5adf743eb5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "afinn.score(texto_neg)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywP43scVuDqv",
        "outputId": "18ea5246-4b98-49df-9522-87cdd12a3459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "afinn.score(texto_pos)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhkDVIxZZpa"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "25) Para você, qual ferramenta teve melhor comportamento?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SWQvthbuG3T"
      },
      "source": [
        "Ao compararmos os três tipos de analises de sentimentos, podemos ver que o Vader possui um score mais detalhado de sentimentos positivos, negativos e neutros, por considerar cada sentença do conjunto de palavras e categoriza elas de acordo com o sentimento. \n",
        "Já o TextBlob trabalha com uma analise mais subjetiva, onde a interpretação de cada sentença deve ser um pouco mais precisa para poder ter uma maior acertiva, por ser uma metodologia baseada em polaridade e subjetividade. Por fim temos o Afinn, é uma abodagem mais direta, onde tem uma biblioteca com um dicionario de palavras e sua classificação como neutra, negativa ou positiva, este modelo não consegue cobrir textos com uma varição grande de palavras, que claro não estejam presentes em seu dicionário."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWImUeS0ZZpb"
      },
      "source": [
        "# Dica:\n",
        "## Quando for trabalhar com um dataset em inglês, a biblioteca Spacy facilita!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONqxhviZZpc",
        "outputId": "d9e23049-4ffe-474f-e5b8-b339f338c53f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4MB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.2.0)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-cp36-none-any.whl size=98051305 sha256=711061e6d2f63f990bb29ed12d213abf9b63c6862d30ad9de402a582b1a39860\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-be5otrmw/wheels/df/94/ad/f5cf59224cea6b5686ac4fd1ad19c8a07bc026e13c36502d81\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hj3KE97ZZph"
      },
      "source": [
        "import spacy\n",
        "import pandas as pd"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW0GLnhVZZpn"
      },
      "source": [
        "O scpay forne um pacote que já tem série de modelos já treinados em NLP. Inclusive para os embeddings em inglês.\n",
        "\n",
        "Para mais informações vá em:\n",
        "\n",
        "https://spacy.io/models/en#en_core_web_md\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v02Lid1QZZpo"
      },
      "source": [
        "Com o método abaixo carregamos um dos modelos do spacy:\n",
        "\n",
        "```python\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "```\n",
        "\n",
        "Para aplicar o modelo, basta passar o texto para o modelo carregado anteriormente:\n",
        "\n",
        "```python\n",
        "doc = nlp(\"This is some text that I am processing with Spacy\")\n",
        "```\n",
        "\n",
        "Carregue o modelo e imprima doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjRx4bZxZZpo",
        "outputId": "f7b0f112-a36b-4644-f48a-698dc1b0dfed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "nlp = spacy.load('en_core_web_md')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-614d6de0ab0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_md'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDsD2THwZZps",
        "outputId": "670f4c93-5414-46ae-b3af-03c4ef5aa70a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "doc = nlp(\"This is some text that I am processing with Spacy\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-28dde4cb9d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This is some text that I am processing with Spacy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDWkp1tfZZpy"
      },
      "source": [
        "doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuqCJaIMZZp3"
      },
      "source": [
        "Ao aplicar o modelo carregado a variável <b> doc </b> já possui os embeddings de cada uma das palavras e o embedding da frase, que é a média de todos vetores de todas palavras.\n",
        "\n",
        "```python\n",
        "#vetor da primeira palavra\n",
        "doc[0].vector\n",
        "#vetor agregado pela média - embedding do documento\n",
        "doc.vector\n",
        "```\n",
        "O código abaixo mostra que a média de uma posição em específico dos embeddings de todas as palavras e a posição do embedding do documento possuem o mesmo valor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r426C5mvZZp4"
      },
      "source": [
        "def calcula_media_posicao(x):\n",
        "    soma = 0\n",
        "    vector = []\n",
        "    for i in range(0,len(doc)):\n",
        "        vector.append(doc[i].vector)    \n",
        "    \n",
        "    for v in vector:\n",
        "        soma += v[x]\n",
        "    return soma/len(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "969rVBBYZZp8"
      },
      "source": [
        "round(calcula_media_posicao(10),6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmkeEtyQZZqB"
      },
      "source": [
        "round(doc.vector[10], 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjZQ_jAMZZqF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
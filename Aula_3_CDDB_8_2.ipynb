{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Aula 3 - CDDB 8_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a4e3c6e97d33497dafc6ea6f95939952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da1a879a0880442d8691b873096a268b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dddce822f7d24dcd9f378162c557621b",
              "IPY_MODEL_abdb244a287d4f65ad85ce1504237760"
            ]
          }
        },
        "da1a879a0880442d8691b873096a268b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dddce822f7d24dcd9f378162c557621b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ab8a74c0ab94e84b253b5b732a06984",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 49459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c650583df5a4c708f4cd795e64dbc97"
          }
        },
        "abdb244a287d4f65ad85ce1504237760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41ff511115974af0bb34e9c11d99c6c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49459/49459 [01:19&lt;00:00, 622.33it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_362bac079ee14398ab781b1b782bff6e"
          }
        },
        "8ab8a74c0ab94e84b253b5b732a06984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c650583df5a4c708f4cd795e64dbc97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41ff511115974af0bb34e9c11d99c6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "362bac079ee14398ab781b1b782bff6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40d878542fea48d49b5082913f4d8fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f4387cfe25744b8e9dd6744caf14bffc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_78297b7f35574c15a0f64327eabc4ad3",
              "IPY_MODEL_7476b16e9ebd4b188f46ebfde86c2332"
            ]
          }
        },
        "f4387cfe25744b8e9dd6744caf14bffc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78297b7f35574c15a0f64327eabc4ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_971442de7b434795bd98a7f014e9644e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 49459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df5f94c6394c4292813b60f01f9d15f4"
          }
        },
        "7476b16e9ebd4b188f46ebfde86c2332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_559c89ab5fcd498688b0bb8aa107fe7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49459/49459 [00:38&lt;00:00, 1292.61it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53e839a9710e4a858c988519089eee2f"
          }
        },
        "971442de7b434795bd98a7f014e9644e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df5f94c6394c4292813b60f01f9d15f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "559c89ab5fcd498688b0bb8aa107fe7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53e839a9710e4a858c988519089eee2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26b6a29f406243c482e8f06c91163205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d21de2083d545699335b192249fa939",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab157d475f09496b99207c5ba763a9f5",
              "IPY_MODEL_a0b9cc66ef314e8db0d9812698c88f25"
            ]
          }
        },
        "9d21de2083d545699335b192249fa939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab157d475f09496b99207c5ba763a9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7455802d1d434bdc8785fd89ede93e4a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 49459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ba5e89cb6ff4282bdd3987cadad6983"
          }
        },
        "a0b9cc66ef314e8db0d9812698c88f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a0492d9cc1949259b6af0d0e183842f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49459/49459 [02:33&lt;00:00, 323.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3acb0f644bd48c781e4221b0a63e8ad"
          }
        },
        "7455802d1d434bdc8785fd89ede93e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ba5e89cb6ff4282bdd3987cadad6983": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a0492d9cc1949259b6af0d0e183842f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3acb0f644bd48c781e4221b0a63e8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Mgum7LZZmf",
        "outputId": "3b92be94-fd61-4c7e-c1ed-4ddcdfdef45b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "!pip install afinn\n",
        "!python -m textblob.download_corpora\n",
        "!pip install -U textblob\n",
        "!pip install vaderSentiment\n",
        "!pip install pyemd\n",
        "!pip install Unidecode"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: afinn in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n",
            "Requirement already up-to-date: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.6/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2020.6.20)\n",
            "Requirement already satisfied: pyemd in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pyemd) (1.18.5)\n",
            "Collecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR9dcTSYZZml",
        "outputId": "435aa7a8-917c-48fb-e6e2-78299de3168f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "from unidecode import unidecode\n",
        "import pandas as pd\n",
        "import bz2\n",
        "import gensim\n",
        "import warnings\n",
        "import numpy as np\n",
        "from gensim.models import word2vec\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.spatial import distance\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "tqdm_notebook.pandas()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjOYV0cfZZmq"
      },
      "source": [
        "# Carregando os embeddings\n",
        "\n",
        "Aqui vamos utilizar os embeddings para realizar as seguintes atividades:\n",
        "\n",
        "- anÃ¡lise de simlaridade\n",
        "- classificaÃ§Ã£o de documentos\n",
        "\n",
        "<b> Carregue os embeddings treinados, como vimos na Aula 2. Ã‰ o mesmo arquivo que iremos utilizar</b>\n",
        "\n",
        "Link: https://drive.google.com/open?id=1zI8pGfbUHuU_0wY_FV4tD6w6ZCUJTQbh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqMDMgrBZZmr"
      },
      "source": [
        "newfilepath = \"embedding_wiki_100d_pt.txt\"\n",
        "filepath = \"/tmp/ptwiki_20180420_100d.txt.bz2\"\n",
        "with open(newfilepath, 'wb') as new_file, bz2.BZ2File(filepath, 'rb') as file:\n",
        "    for data in iter(lambda : file.read(100 * 1024), b''):\n",
        "        new_file.write(data)\n",
        "\n",
        "#carregar\n",
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(newfilepath, binary=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqZJuktuZZmv"
      },
      "source": [
        "# Similaridade de Documentos\n",
        "\n",
        "Para realizar a similaridade entre documentos, utilize as frases abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-YjfkcTZZmw"
      },
      "source": [
        "frase1 = \"Excelente produto chegou antes do prazo indico e recomendo produto bom pois jÃ¡ testei e foi mais que aprovado\" \n",
        "frase2 = \"SUPER RECOMENDO, PREÃ‡O, QUALIDADE #BRASTEMP, EFICIÃŠNCIA NA ENTREGA, E FACILIDADE DE PAGAMENTO. MUITO BOM!!!\"\n",
        "frase3 = \"A tampa do fogÃ£o veio com problemas com o pino de encaixe solto e precisa de reparos\"\n",
        "frase4 = \"FogÃ£o Ã³timo!\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNGfjS5RZZm1"
      },
      "source": [
        "## DistÃ¢ncia de Jaccard\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "1) FaÃ§a um mÃ©todo que calcule a similaridade de Jaccard e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n",
        "\n",
        "ObservaÃ§Ã£o: lembrando que vocÃª precisa aplicar um pre-processamento nessas frases antes de aplicar o mÃ©todo.\n",
        "FaÃ§a:\n",
        "\n",
        "- Lower\n",
        "- RemoÃ§Ã£o StopWords\n",
        "- RemoÃ§Ã£o PontuaÃ§Ã£o\n",
        "- TokenizaÃ§Ã£o"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn2YYL7bZZm2",
        "outputId": "a72cb3dd-405c-4b9e-84f0-d69d2386ccf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def pre_processamento_texto(corpus):\n",
        "    corpus_alt  = re.findall(r\"\\w+(?:'\\w+')?|[^\\w\\s]\",corpus)\n",
        "    corpus_alt  = [t.lower() for t in corpus_alt] \n",
        "    lista_stops = stopwords.words(\"portuguese\")\n",
        "    corpus_alt  = [token for token in corpus_alt if token not in lista_stops]\n",
        "    corpus_alt  = [re.sub(r\"\\d\",\"\", token) for token in corpus_alt]\n",
        "    corpus_alt  = [token for token in corpus_alt if token not in string.punctuation]\n",
        "    corpus_alt  = [unidecode(token) for token in corpus_alt]\n",
        "    return corpus_alt\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['excelente', 'produto', 'chegou', 'antes', 'prazo', 'indico', 'recomendo', 'produto', 'bom', 'pois', 'testei', 'aprovado']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kws6GdxVy0P"
      },
      "source": [
        "###\n",
        "# Pre_processamento de palavras das frases, removendo stopwords e acentos, pontuaÃ§Ãµes\n",
        "# e retorna tokens em minusculo\n",
        "###\n",
        "\n",
        "frase1_pre = pre_processamento_texto(frase1)\n",
        "frase2_pre = pre_processamento_texto(frase2)\n",
        "frase3_pre = pre_processamento_texto(frase3)\n",
        "frase4_pre = pre_processamento_texto(frase4)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZJrrzMWWgYR",
        "outputId": "92df3fd2-5b95-4eb5-8ebc-9785075dbc2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Jaccard = IntercessÃ£o / UniÃ£o\n",
        "\n",
        "def jaccard_method(f1, f2): \n",
        "    return len(set(f1).intersection(set(f2)))/len(set(f1).union(set(f2)))\n",
        "\n",
        "# Frase1 e Frase2\n",
        "# Frase1 e Frase3\n",
        "# Frase2 e Frase3\n",
        "# Frase1 e Frase4\n",
        "print(jaccard_method(frase1_pre, frase2_pre))\n",
        "print(jaccard_method(frase1_pre, frase3_pre))\n",
        "print(jaccard_method(frase2_pre, frase3_pre))\n",
        "print(jaccard_method(frase1_pre, frase4_pre))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.10526315789473684\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke1PVggcZZm8"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "2) Qual par de frase teve maior simlaridade? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g7wRRl_ZZm9"
      },
      "source": [
        "O par frase1 e frase2 possuÃ­ maior similaridade por conter dentro de seus tokens (palavras) semelhanÃ§as de uma com a outra, o que nÃ£o ocorre com as demais palavras. Portanto, este resultado faz sentindo uma vez que a intercessÃ£o de palavras distintas Ã© 0 entre as demais frases testadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND3usAELZZm-"
      },
      "source": [
        "## DistÃ¢ncia de Cosseno\n",
        "\n",
        "Aqui iremos calcular a distÃ¢ncia do cosseno utilizando duas formas, que aprendemos na aula passada, para representar o texto.\n",
        "\n",
        "- Bag of Words (BOW) \n",
        "- Embedding\n",
        "\n",
        "ObservaÃ§Ã£o:\n",
        "\n",
        "Existem duas formas de trabalhar com o cosseno:\n",
        "\n",
        "<b> DistÃ¢ncia </b>: quanto menor mais perto estÃ£o as frases.\n",
        "<b> Similaridade </b>: quanto maior mais perto estÃ£o as frases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Qw93ZLZZm-"
      },
      "source": [
        "### BOW - DistÃ¢ncia do cosseno\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "3) Calcule a distÃ¢ncia do cosseno utilizando a representaÃ§Ã£o CountVectorizer e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n",
        "\n",
        "ObservaÃ§Ã£o: no CountVectorizer utilizem as frases jÃ¡ pre-processadas da atividade anterior. Mas para aplicÃ¡-las no fit_transform, cada frase deve ser um string (sem estar tokenizada) dentro de uma lista.\n",
        "\n",
        "```python\n",
        "#exemplo\n",
        "distance.cosine(frase1, frase2)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CzqpPPGZZm_"
      },
      "source": [
        "bow = CountVectorizer()\n",
        "\n",
        "vector = bow.fit_transform([' '.join(frase1_pre), \n",
        "                            ' '.join(frase2_pre),\n",
        "                            ' '.join(frase3_pre),\n",
        "                            ' '.join(frase4_pre)])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RsTI3KRak69",
        "outputId": "8f1e809b-d7f8-4329-b066-6d7c2c6206b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vector.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHh3dHRMa3Xj",
        "outputId": "e7252c84-2fad-4b33-8ccb-49eda29298e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "pd.DataFrame(vector.todense())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0   1   2   3   4   5   6   7   8   ...  20  21  22  23  24  25  26  27  28\n",
              "0   1   1   1   0   1   0   0   0   1  ...   2   0   1   0   0   0   0   1   0\n",
              "1   0   0   1   1   0   1   0   1   0  ...   0   1   1   0   0   1   0   0   0\n",
              "2   0   0   0   0   0   0   1   0   0  ...   0   0   0   1   1   0   1   0   1\n",
              "3   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0\n",
              "\n",
              "[4 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IctZjSGYd5CU"
      },
      "source": [
        "frase1_bow = vector.todense()[0]\n",
        "frase2_bow = vector.todense()[1]\n",
        "frase3_bow = vector.todense()[2]\n",
        "frase4_bow = vector.todense()[3]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZoOGjaAd-I5",
        "outputId": "561bf0bd-37a3-4f77-ed9e-4f58cdcbc841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(distance.cosine(frase1_bow,frase2_bow))\n",
        "print(distance.cosine(frase1_bow,frase3_bow))\n",
        "print(distance.cosine(frase2_bow,frase3_bow))\n",
        "print(distance.cosine(frase1_bow,frase4_bow))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8309691490542968\n",
            "1.0\n",
            "1.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcFS1MKzZZnE"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "\n",
        "4) Qual par de frase teve maior distÃ¢ncia? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buNHHZPgZZnF"
      },
      "source": [
        "As frases f1 - f3, f1 - f4, f2 - f3, tiveram resultados cosseno iguais a 1.0, o que nos mostra que sua similaridade Ã© nula, podemos ver que ao abrir estas frases, as palavras usadas, sÃ£o distintas. A menor distÃ¢ncia cosseno foi da frase1 e frase2, exatamente como esperado, pois estas frases tem palavras em comum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3G4ckzlZZnN"
      },
      "source": [
        "### Embedding - DistÃ¢ncia do cosseno\n",
        "\n",
        "Para calcular o embedding de cada uma das frases, utilize o modelo carregado inicialmente. \n",
        "\n",
        "Cada palavra tem um vetor, para formar o embedding da frase tire a mÃ©dia de todos os vetores.\n",
        "\n",
        "Utilize as frases jÃ¡ pre-processadas\n",
        "\n",
        "<b> Atividade </b> \n",
        "\n",
        "5) Calcule a distÃ¢ncia do cosseno utilizando a representaÃ§Ã£o Embedding e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRO8RnLgZZnO",
        "outputId": "a0cec997-1e37-4f87-ce87-42324b7834f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean(np.array([word_vectors[palavra] for palavra in frase1_pre]), axis=0).shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns8jgP8DfoBk",
        "outputId": "2363863e-061b-473a-f7f2-a31141913bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "word_vectors[\"testei\"]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.7639,  0.3701, -0.8806, -0.2736, -1.1103,  0.4136,  0.147 ,\n",
              "        0.6423, -0.1022,  0.5495, -0.1379,  0.8172, -0.4062,  0.0082,\n",
              "       -0.3987,  0.6067,  0.5797, -0.3458, -0.3474, -0.3411, -0.2711,\n",
              "        0.3904, -0.466 ,  0.1123, -0.0695, -0.1692, -0.3848, -0.4922,\n",
              "       -0.7122,  0.402 ,  0.2955, -0.5608,  0.976 ,  0.5732, -0.0393,\n",
              "       -0.0741,  0.4224,  0.319 ,  0.5793, -0.2527,  0.5185, -0.2147,\n",
              "       -0.3736, -0.5574,  0.3233, -0.1902, -0.6013, -0.0891, -1.021 ,\n",
              "        0.777 ,  0.3467,  0.046 ,  0.2413, -0.4255,  0.4669, -0.1585,\n",
              "       -0.3398,  0.3088, -0.0472,  0.4295,  0.9259, -0.0159, -0.3963,\n",
              "        0.1668,  0.0899, -0.0103,  0.1233,  0.9663, -0.3848,  0.3967,\n",
              "       -0.5887,  0.8346,  0.2106, -0.6855, -0.0744, -0.4362, -0.8564,\n",
              "        0.2475,  0.1882,  0.1293, -0.3085, -0.6424, -0.9031, -0.1352,\n",
              "       -0.3293,  0.5941, -0.0351, -0.0781,  0.5484,  0.7644,  0.3971,\n",
              "        0.0968,  0.2734,  0.3265,  0.2035,  0.2835,  0.173 , -0.3811,\n",
              "       -0.1333, -0.2788], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdCIu5zQf57a",
        "outputId": "fcf5375e-d53b-41f0-8662-e596976c217a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array([word_vectors[palavra] for palavra in frase1_pre]).shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8JzSLlJfxWu"
      },
      "source": [
        "def get_embedding(f):\n",
        "    return np.mean(np.array([word_vectors[palavra] for palavra in f if palavra in word_vectors.vocab]), axis=0)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TEm5Q3-gD29"
      },
      "source": [
        "frase1_emb = get_embedding(frase1_pre)\n",
        "frase2_emb = get_embedding(frase2_pre)\n",
        "frase3_emb = get_embedding(frase3_pre)\n",
        "frase4_emb = get_embedding(frase4_pre)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2a5J1_dgM8B",
        "outputId": "d693a6d9-b851-4857-bff1-d9845cb94a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(distance.cosine(frase1_emb,frase2_emb))\n",
        "print(distance.cosine(frase1_emb,frase3_emb))\n",
        "print(distance.cosine(frase2_emb,frase3_emb))\n",
        "print(distance.cosine(frase1_emb,frase4_emb))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.15136468410491943\n",
            "0.21427351236343384\n",
            "0.24302351474761963\n",
            "0.32684141397476196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgZWHiGSZZnT"
      },
      "source": [
        "<b>Atividade </b>\n",
        "\n",
        "6) Qual par de frase teve maior distÃ¢ncia? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsFFxOoeZZnU"
      },
      "source": [
        "O resultado foi similar ao apresentado na questÃ£o anterior, as maiores distÃ¢ncias foram das frases que nada tem em comum e a frase 1 e frase 2, que possuem suas similaridades, tiveram uma distÃ¢ncia mais considerÃ¡vel. Vale lembrar que apÃ³s aplicar o embedding as palavras prÃ©-processadas, ganharam um peso extra que pode explicar alguns valores prÃ³ximos de 0.20 que representaria um certo grau de similaridade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx5acLVhZZne"
      },
      "source": [
        "## WMD\n",
        "\n",
        "O WMD jÃ¡ estÃ¡ incorporado ao Word2Vec\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "7) Calcule a distÃ¢ncia WMD e aplique para os seguintes pares de frases:\n",
        "\n",
        "- Frase1 e Frase2\n",
        "- Frase1 e Frase3\n",
        "- Frase2 e Frase3\n",
        "- Frase1 e Frase4\n",
        "\n",
        "ObservaÃ§Ã£o: use a variÃ¡vel jÃ¡ tokenizada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0881q7vZZne",
        "outputId": "059a264c-57ed-470b-e04f-f43d2452c06c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Frase 1 e 2 \",word_vectors.wmdistance(frase1_pre, frase2_pre))\n",
        "print(\"Frase 1 e 3 \",word_vectors.wmdistance(frase1_pre, frase3_pre))\n",
        "print(\"Frase 2 e 3 \",word_vectors.wmdistance(frase2_pre, frase3_pre))\n",
        "print(\"Frase 1 e 4 \",word_vectors.wmdistance(frase1_pre, frase4_pre))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frase 1 e 2  3.0444450580164455\n",
            "Frase 1 e 3  3.715277379918346\n",
            "Frase 2 e 3  3.7981251887017256\n",
            "Frase 1 e 4  4.125106107605237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsIENn25ZZni"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "8) Qual par de frase teve maior distÃ¢ncia? E qual teve menor? Este resultado faz sentido? Explique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhC4OvGWZZnj"
      },
      "source": [
        "Novamente, temos os valores se repetindo onde a frase com maior similaridade possui um valor menor de WMD que quanto maior seu Ã­ndice maior Ã© seu nÃ­vel de dessimilaridade ou desigualdade entre as frases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXHGivtDZZnk"
      },
      "source": [
        "# ClassificaÃ§Ã£o de Documentos\n",
        "\n",
        "A clssificaÃ§Ã£o de documentos Ã© muito Ãºtil em vÃ¡rios aspectos. Um dos tipos de classificaÃ§Ã£o de texto Ã© a anÃ¡lise de sentimentos.\n",
        "\n",
        "A fim de ilustrar a classificaÃ§Ã£o de documentos iremos criar um modelo para classificar uma frase como positiva ou negativa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhCOoEn7ZZno"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "9) Carregue o dataset com o pandas e depois dÃª o head no dataframe.\n",
        "\n",
        "\n",
        "Link download: https://drive.google.com/open?id=15azJWdEEPGsXQGiDmEOseTBJcquWvBQc\n",
        "\n",
        "<b> Este dataset Ã© sobre revisÃµes de filmes do IMDB. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI0oXiOoZZnp"
      },
      "source": [
        "df = pd.read_csv(\"/tmp/imdb-reviews-pt-br.csv\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJYAOZecZZnv",
        "outputId": "0a6e4383-7d3b-491a-ba6b-72d38283b4d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df[\"sentiment\"].value_counts()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neg    24765\n",
              "pos    24694\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCKr5KPMZZnz"
      },
      "source": [
        "## RepresentaÃ§Ã£o dos dados\n",
        "\n",
        "O sentimento positivo e negativo iremos binarizar cada um deles. Seja 1 positivo e 0 negativo.\n",
        "\n",
        "Iremos representar o texto de duas formas:\n",
        "\n",
        "- Bag of Words (BOW)\n",
        "- Embedding\n",
        "\n",
        "Depois iremos comparar o resultado de cada um deles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POkSAiYMZZn0"
      },
      "source": [
        "### RepresentaÃ§Ã£o Target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0mYbWgcZZn1"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "10) FaÃ§a a representaÃ§Ã£o dos sentimentos. 1 positivo; 0 negativo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBkDjo4VZZn2"
      },
      "source": [
        "target = df[\"sentiment\"].replace([\"neg\",\"pos\"],[0,1])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jD5OChwpEtI",
        "outputId": "ccf8c7a8-f3d5-46a4-a73c-fcf8faa7bd3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49459,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8VgGgUnZZn8"
      },
      "source": [
        "### Bag of Words (BOW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xirBWWCzZZn-"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "11) Aplique o prÃ©-processamento listado abaixo na coluna ``text_pt`` (crie uma nova coluna ```text_pt_sem_stopwords``` no dataframe para armazenar este dado processado):\n",
        "\n",
        "- Remova as stopwords do texto\n",
        "- Remova as pontuÃ§Ãµes\n",
        "- Mantenha o texto sem tokenizaÃ§Ã£o, ou seja uma string\n",
        "\n",
        "<b> Dica: </b> use o ```progress_apply``` para exibir a barra de progresso:\n",
        "\n",
        "```python\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "df[\"colunas\"].progress_apply(lambda x: preprocessamento(x))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHLMsY9WpSC5"
      },
      "source": [
        "def pre_processamento_texto_return_str(corpus):\n",
        "    \n",
        "    corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\",corpus)\n",
        "    \n",
        "    lista_stopwords = stopwords.words(\"portuguese\")\n",
        "    corpus_alt = [t for t in corpus_alt if t not in lista_stopwords]\n",
        "    corpus_alt = [t for t in corpus_alt if t not in string.punctuation]\n",
        "    \n",
        "    corpus_alt = [re.sub(r'\\d', '', t) for t in corpus_alt]\n",
        "    \n",
        "    corpus_alt_str = ' '.join(corpus_alt)\n",
        "    \n",
        "    return corpus_alt_str.lower()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnJokm8VZZn-",
        "outputId": "0b204200-4331-4a67-e5d2-a7ffdeb7ce65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "a4e3c6e97d33497dafc6ea6f95939952",
            "da1a879a0880442d8691b873096a268b",
            "dddce822f7d24dcd9f378162c557621b",
            "abdb244a287d4f65ad85ce1504237760",
            "8ab8a74c0ab94e84b253b5b732a06984",
            "9c650583df5a4c708f4cd795e64dbc97",
            "41ff511115974af0bb34e9c11d99c6c4",
            "362bac079ee14398ab781b1b782bff6e"
          ]
        }
      },
      "source": [
        "df[\"text_pt_sem_stopwords\"] = df[\"text_pt\"].progress_apply(lambda x: pre_processamento_texto_return_str(x))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4e3c6e97d33497dafc6ea6f95939952",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=49459.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cvh4Hx5pqvT",
        "outputId": "a05f2d91-6e34-4945-b926-58986b055fa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text_en</th>\n",
              "      <th>text_pt</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_pt_sem_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
              "      <td>neg</td>\n",
              "      <td>mais vez sr costner arrumou filme tempo necess...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>Este Ã© um exemplo do motivo pelo qual a maiori...</td>\n",
              "      <td>neg</td>\n",
              "      <td>este exemplo motivo maioria filmes aÃ§Ã£o mesmos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>primeiro tudo odeio raps imbecis poderiam agir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>Nem mesmo os Beatles puderam escrever mÃºsicas ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>nem beatles puderam escrever mÃºsicas todos gos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
              "      <td>Filmes de fotos de latÃ£o nÃ£o Ã© uma palavra apr...</td>\n",
              "      <td>neg</td>\n",
              "      <td>filmes fotos latÃ£o palavra apropriada verdade ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                              text_pt_sem_stopwords\n",
              "0   1  ...  mais vez sr costner arrumou filme tempo necess...\n",
              "1   2  ...  este exemplo motivo maioria filmes aÃ§Ã£o mesmos...\n",
              "2   3  ...  primeiro tudo odeio raps imbecis poderiam agir...\n",
              "3   4  ...  nem beatles puderam escrever mÃºsicas todos gos...\n",
              "4   5  ...  filmes fotos latÃ£o palavra apropriada verdade ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TddT2Y6JZZoC"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "12) Aplique a representaÃ§Ã£o do texto processado anteriormente com CountVectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axSZo69tZZoC"
      },
      "source": [
        "bow = CountVectorizer()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qexsujompyQt"
      },
      "source": [
        "x_bow = bow.fit_transform(df[\"text_pt_sem_stopwords\"])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz6rQ5ptp09b"
      },
      "source": [
        "vetor = bow.fit_transform([' '.join(frase1_pre),\n",
        "                    ' '.join(frase2_pre),\n",
        "                    ' '.join(frase3_pre),\n",
        "                    ' '.join(frase4_pre)])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfDfqt3Mp8or"
      },
      "source": [
        "X_bow = bow.fit_transform(df[\"text_pt_sem_stopwords\"])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCCJdak3p_2j",
        "outputId": "e9591868-d615-48c0-d929-f9853929002b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_bow.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49459, 127624)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mELsQ0tvZZoF"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSUe-Yr_ZZoG"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "13) Aplique o prÃ©-processamento listado abaixo na coluna ``text_pt`` (crie uma nova coluna ```text_pt_sem_stopwords_token``` no dataframe para armazenar este dado processado):\n",
        "\n",
        "- Aplique lower\n",
        "- Remova as stopwords do texto\n",
        "- Remova as pontuÃ§Ãµes\n",
        "- Mantenha o texto com tokenizaÃ§Ã£o\n",
        "\n",
        "<b> Dica: </b> use o ```progress_apply``` para exibir a barra de progresso:\n",
        "\n",
        "```python\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "df[\"colunas\"].progress_apply(lambda x: preprocessamento(x))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBJxB_SsZZoH"
      },
      "source": [
        "def pre_processamento_texto_return_token(corpus):\n",
        "    \n",
        "    corpus_alt = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\",corpus)\n",
        "    \n",
        "    lista_stopwords = stopwords.words(\"portuguese\")\n",
        "    corpus_alt = [t for t in corpus_alt if t not in lista_stopwords]\n",
        "    corpus_alt = [t for t in corpus_alt if t not in string.punctuation]\n",
        "    \n",
        "    corpus_alt = [re.sub(r'\\d', '', t) for t in corpus_alt]\n",
        "    \n",
        "    \n",
        "    return corpus_alt"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqEH_gGaqHL0",
        "outputId": "d790708f-2167-42ea-d402-2317fbcddf70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "40d878542fea48d49b5082913f4d8fc1",
            "f4387cfe25744b8e9dd6744caf14bffc",
            "78297b7f35574c15a0f64327eabc4ad3",
            "7476b16e9ebd4b188f46ebfde86c2332",
            "971442de7b434795bd98a7f014e9644e",
            "df5f94c6394c4292813b60f01f9d15f4",
            "559c89ab5fcd498688b0bb8aa107fe7a",
            "53e839a9710e4a858c988519089eee2f"
          ]
        }
      },
      "source": [
        "df[\"text_pt_sem_stopwords_token\"] = df[\"text_pt\"].progress_apply(lambda x: pre_processamento_texto_return_token(x))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40d878542fea48d49b5082913f4d8fc1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=49459.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YipHX6zVqMfY",
        "outputId": "1e97cef3-bfa3-4f80-883e-5809e5d1fe50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text_en</th>\n",
              "      <th>text_pt</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_pt_sem_stopwords</th>\n",
              "      <th>text_pt_sem_stopwords_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
              "      <td>neg</td>\n",
              "      <td>mais vez sr costner arrumou filme tempo necess...</td>\n",
              "      <td>[Mais, vez, Sr, Costner, arrumou, filme, tempo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>Este Ã© um exemplo do motivo pelo qual a maiori...</td>\n",
              "      <td>neg</td>\n",
              "      <td>este exemplo motivo maioria filmes aÃ§Ã£o mesmos...</td>\n",
              "      <td>[Este, exemplo, motivo, maioria, filmes, aÃ§Ã£o,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>primeiro tudo odeio raps imbecis poderiam agir...</td>\n",
              "      <td>[Primeiro, tudo, odeio, raps, imbecis, poderia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>Nem mesmo os Beatles puderam escrever mÃºsicas ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>nem beatles puderam escrever mÃºsicas todos gos...</td>\n",
              "      <td>[Nem, Beatles, puderam, escrever, mÃºsicas, tod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
              "      <td>Filmes de fotos de latÃ£o nÃ£o Ã© uma palavra apr...</td>\n",
              "      <td>neg</td>\n",
              "      <td>filmes fotos latÃ£o palavra apropriada verdade ...</td>\n",
              "      <td>[Filmes, fotos, latÃ£o, palavra, apropriada, ve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                        text_pt_sem_stopwords_token\n",
              "0   1  ...  [Mais, vez, Sr, Costner, arrumou, filme, tempo...\n",
              "1   2  ...  [Este, exemplo, motivo, maioria, filmes, aÃ§Ã£o,...\n",
              "2   3  ...  [Primeiro, tudo, odeio, raps, imbecis, poderia...\n",
              "3   4  ...  [Nem, Beatles, puderam, escrever, mÃºsicas, tod...\n",
              "4   5  ...  [Filmes, fotos, latÃ£o, palavra, apropriada, ve...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZPhMIrWZZoM"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "14) Aplique a representaÃ§Ã£o do texto com Embeddings. Cada palavra tem um embedding, o embedding da frase Ã© a mÃ©dia de todos embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4gg0S5NZZoM",
        "outputId": "a30e73b1-cbbe-4ef4-ea58-85b79f97a2ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "26b6a29f406243c482e8f06c91163205",
            "9d21de2083d545699335b192249fa939",
            "ab157d475f09496b99207c5ba763a9f5",
            "a0b9cc66ef314e8db0d9812698c88f25",
            "7455802d1d434bdc8785fd89ede93e4a",
            "8ba5e89cb6ff4282bdd3987cadad6983",
            "5a0492d9cc1949259b6af0d0e183842f",
            "d3acb0f644bd48c781e4221b0a63e8ad"
          ]
        }
      },
      "source": [
        "X_embedding = df[\"text_pt_sem_stopwords_token\"].progress_apply(lambda x: get_embedding(x))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26b6a29f406243c482e8f06c91163205",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=49459.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3baiAE77qa5p",
        "outputId": "9ed767a3-208d-4b3c-e08d-6cb84a5e8501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_embedding.head()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [0.1722594, 0.20761016, -0.053872462, -0.22401...\n",
              "1    [0.17371698, 0.187417, -0.064705655, -0.208970...\n",
              "2    [0.23271771, 0.13545005, -0.0045176437, -0.179...\n",
              "3    [0.26263848, 0.13604508, -0.07352549, -0.20097...\n",
              "4    [0.21992578, 0.10650969, -0.09349515, -0.14721...\n",
              "Name: text_pt_sem_stopwords_token, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smuMLA5Aqhnv",
        "outputId": "01c7d344-18de-46b1-b262-d3a034e4dfa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_embedding)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49459"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqPJf0yLZZoQ"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_xhW7e2ZZoQ"
      },
      "source": [
        "### CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpcc167FZZoR"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "15) FaÃ§a a divisÃ£o dados dados em treino e teste como no exemplo abaixo:\n",
        "\n",
        "```python\n",
        "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bag, target,random_state=123)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3MeGchRZZoS"
      },
      "source": [
        "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bow, target, random_state=123)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kuekl8WqrlW",
        "outputId": "def7bcad-187d-47d0-d3e9-45a689922fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_bow"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<49459x127624 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 5267081 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1--rXvwqtta",
        "outputId": "c8f776d8-29a8-4f17-c292-6213dd0e29f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train_bow"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<37094x127624 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 3944594 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXsZHGmhqvgD",
        "outputId": "dd44b1a6-2c52-4b5d-d664-74a3214df719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_test_bow"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<12365x127624 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1322487 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0ggm8ZLZZoY"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "16) Treine com uma regressÃ£o logÃ­stica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJN8KMHiZZoa"
      },
      "source": [
        "modelo = LogisticRegression()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppohJIQSq9TY",
        "outputId": "0e95e19e-8566-46ed-a8f9-f18cf9a0da6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "modelo.fit(X_train_bow, y_train_bow)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivlITfC2ZZof"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "17) Calcule as mÃ©tricas de resultado utilizando mÃ©todo abaixo:\n",
        "\n",
        "```python\n",
        "print(classification_report(y_test_bow, y_pred))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsfRxqjSZZog",
        "outputId": "2b252405-8de9-4658-f1b1-ca2a01101a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "modelo.predict(X_test_bow)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug7cB5_0rDWU"
      },
      "source": [
        "predicoes = modelo.predict(X_test_bow)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMfevLZarGoP",
        "outputId": "93e64b7d-fe16-4a7a-9deb-90e785aee3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test_bow.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12365,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtgNXONPrLO7",
        "outputId": "15d0b15f-93db-4fe9-f3b6-8a095339ef00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test_bow, predicoes))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.88      6112\n",
            "           1       0.87      0.89      0.88      6253\n",
            "\n",
            "    accuracy                           0.88     12365\n",
            "   macro avg       0.88      0.88      0.88     12365\n",
            "weighted avg       0.88      0.88      0.88     12365\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiulNTGNZZoj"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6abN65iqZZok"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "18) FaÃ§a a divisÃ£o dados dados em treino e teste como no exemplo abaixo:\n",
        "\n",
        "Verifique o shape do X treino e X teste. Caso eles estejam com apenas uma dimensÃ£o, vocÃª precisa tranformÃ¡-los para duas dimensÃµes, caso contrÃ¡rio ocorrerÃ¡ erro no treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn57b04_ZZol"
      },
      "source": [
        "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(X_embedding, target, random_state=123)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7ggFhuQrTvt",
        "outputId": "5d6766a7-dac6-48ac-8eae-a92feb82f53e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_train_emb)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37094"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4nY3d0ormEn",
        "outputId": "bddd563a-668f-4e2e-9b38-8b21693bc5f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(y_train_emb)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37094"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9BR0H7fZZop"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "19) Treine com uma regressÃ£o logÃ­stica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJI29fY2ZZoq"
      },
      "source": [
        "modelo_regressao = LogisticRegression()"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNJJKf6ZrrOE",
        "outputId": "4ecdc3b4-88a2-436a-cc9f-08c4fbe87ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_emb.shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37094,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGdTWBuPrtZe"
      },
      "source": [
        "X_train_emb = pd.DataFrame([x for x in X_train_emb])"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdLgXc_wrw1r",
        "outputId": "f96f41cb-2ce1-4078-9de3-493bb66c1236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_emb.shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37094, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNR7_TRcr1AZ"
      },
      "source": [
        "X_test_emb = pd.DataFrame([x for x in X_test_emb])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3sO5Zhwr3kb",
        "outputId": "e40a4e55-a724-4cf1-8cad-5209e3413de5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test_emb.shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12365, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io1HbFySr5yA",
        "outputId": "da20f581-c9bd-4b1f-fb59-09c60b6290cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "modelo.fit(X_train_emb, y_train_emb)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvIYI1lJZZow"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "20) Calcule as mÃ©tricas de resultado utilizando mÃ©todo abaixo:\n",
        "\n",
        "```python\n",
        "print(classification_report(y_test_bow, y_pred))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClFB32whZZox"
      },
      "source": [
        "#### Calcule as mÃ©tricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-dRYhR_ZZoy"
      },
      "source": [
        "predicoes = modelo.predict(X_test_emb)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4f6iRglsBIx",
        "outputId": "b876368d-e6e6-48f9-c255-9cf8bb35e2ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test_bow, predicoes))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.78      0.78      6112\n",
            "           1       0.78      0.77      0.78      6253\n",
            "\n",
            "    accuracy                           0.78     12365\n",
            "   macro avg       0.78      0.78      0.78     12365\n",
            "weighted avg       0.78      0.78      0.78     12365\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tqiPbcqsKkM"
      },
      "source": [
        "modelo = modelo.predict(X_test_emb)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r9fF_EpsNOd",
        "outputId": "5834677b-dd93-46bc-bf3e-9b2a31c16ed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test_emb, modelo))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.78      0.78      6112\n",
            "           1       0.78      0.77      0.78      6253\n",
            "\n",
            "    accuracy                           0.78     12365\n",
            "   macro avg       0.78      0.78      0.78     12365\n",
            "weighted avg       0.78      0.78      0.78     12365\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sp62Sb1ZZo1"
      },
      "source": [
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "21) Compare os resultados obtidos com o BagOfWords e com o Embedding. Explique os possÃ­veis motivos desta diferenÃ§a."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RShZ0680ZZo2"
      },
      "source": [
        "A estrutura do BOW permite se criar vetores com a relaÃ§Ã£o de cada palavra e dar um \"peso\" para esta relaÃ§Ã£o, o que pode ser uma explicaÃ§Ã£o para a diferenÃ§a de acertos entre este modelo e o tipo Embedding, que neste caso apresenta pouca eficiÃªncia por, talvez, faltar atributos de especificidade dentro do modelo para que ele possa ser mais acertivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-oH0GQfZZo3"
      },
      "source": [
        "# AnÃ¡lise de sentimentos\n",
        "\n",
        "O modelo que criamos anteriormente Ã© para ilustrar como podemos realizar classificaÃ§Ã£o de documentos.\n",
        "Quando a tarefa Ã© sobre anÃ¡lise de sentimentos, temos duas opÃ§Ãµes: treinar nosso prÃ³prio modelo, como feito anteriormente ou utilizar uma das inÃºmeras ferramentas prontas.\n",
        "\n",
        "Vamos testar as seguintes ferramentas:\n",
        "\n",
        "- Vader\n",
        "- Textblob\n",
        "- Affin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilpNXE0cZZo3"
      },
      "source": [
        "Nesta atividade iremos utilizar as duas variÃ¡veis abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq0dLI9JZZo4"
      },
      "source": [
        "texto_neg = df.loc[0, \"text_en\"]\n",
        "texto_pos = df.loc[49431, \"text_en\"]"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhXGLUM_trGv",
        "outputId": "db56acc1-05fb-48fb-f574-f28e9a656ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "texto_neg"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costners character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks hes better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutchers ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvvn2dCXtsas",
        "outputId": "7b876b56-3311-4d0e-8897-73970a09c0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "texto_pos"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'SPOILERS THROUGH: I really am in the minority on this one but I liked this movie. Its not a classic but its definitely involving and quite an adrenalin fueled ride. I definitely thought it was worth at least a 7 rating.Perhaps the reason I liked it is because I havent seen the original.Something tells me that with a movie like this its strongest fans will be the people who have not seen the original version and thus, have little to compare it to. This was not a masterpiece but I did get into it quite a lot and it actually made me want to see the original.There were a few things I liked about it. One was the casting of Kowalkski. Viggo Mortenson was superb and really brought a lot of charisma to the role. Since the bulk of the movie fell on his shoulders, he really needed to be excellent and he was. This was a great role for him.Another interesting thing about Vansishing Point was the fact that its made for television. I had no idea this was the case when watching it. It sure seemed like a major motion picture and I would never have guessed this was not a big screen release.I also found the story to be very absorbing. Im not one for action movies but I got sucked into this. Plus it was a lot more then an action movie in that there was drama, mysticism, a love story, quirky people every which way you turned. I didnt even recognize Priestly. And it was touching. This was not a great movie but it is watchable.And then theres the ending. It packs a strong punch and if ones been involved in the story up to that point, its very difficult not to be transfixed at the very end. I am not sure how I feel about the ending. The implication was that Kowalkski survived and though Im highly skeptical of HOW that would be possible, it is a movie and realism isnt an ingredient thats always in the mix when making a movie.So Id have to say I found the end incredibly unrealistic but very touching in a manipulative kind of way, which I dont usually like but for some reason, is almost forgivable in this movie. Admittedly, a lot of things were just props for the plotcould the villains have been anymore stereotypical? But the makers got a lot right even if they got many things wrong as well. However, having said that, I will admit I can understand why someone whos a major fan of the original would hate this version because, though I have not seen the original, I have seen many original movies I loved being remade with terrible results. My big dislike is actually sequels. But I can understand the low ratings if the original is of that high a quality.People have compared this to Smoky and the Bandit. How about a road version of \"Legends Of The Fall\" meets \"Thelma and Louese\" as well? I sure felt touches of both filmsboth of which Im a fan of. I do not think however, that this was a great film. It was better then average to me but far from great. But it was an absorbing, adrenalin fueled, touching movie with excellent casting of the main character. My vote is 7 of 10.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dB-FuBgZZo9"
      },
      "source": [
        "## Vader\n",
        "\n",
        "<b> Apenas InglÃªs </b>\n",
        "\n",
        "O VADER (Valence Aware Dictionary e sEntiment Reasoner) Ã© uma ferramenta de anÃ¡lise de sentimentos baseada em regras e lÃ©xico, especificamente identifica os sentimentos expressos nas mÃ­dias sociais.\n",
        "\n",
        "- positive sentiment: compound score >= 0.05\n",
        "- neutral sentiment: (compound score > -0.05) e (compound score < 0.05)\n",
        "- negative sentiment: compound score <= -0.05\n",
        "\n",
        "Mais informaÃ§Ãµes: https://github.com/cjhutto/vaderSentiment\n",
        "\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "22) Aplique este mÃ©todo nas revisÃµes ```texto_pos``` e ```texto_neg```.\n",
        "Para aplicar:\n",
        "\n",
        "```python\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "analyzer.polarity_scores(texto)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZE5KL-9ZZo9"
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzsgloUpZZpB"
      },
      "source": [
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHl2CCjRtzTd",
        "outputId": "2c0af014-5128-427a-cb01-013cf4995679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "analyzer.polarity_scores(texto_neg)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.3958, 'neg': 0.126, 'neu': 0.76, 'pos': 0.114}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL9dwIWyt2FJ",
        "outputId": "b9e4a0a2-7c54-4692-f6fb-26fdd74f9f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "analyzer.polarity_scores(texto_pos)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.9969, 'neg': 0.084, 'neu': 0.737, 'pos': 0.179}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDrJTCfKZZpE"
      },
      "source": [
        "## TextBlob\n",
        "\n",
        "<b> Apenas inglÃªs </b>\n",
        "\n",
        "https://www.presentslide.in/2019/08/sentiment-analysis-textblob-library.html\n",
        "\n",
        "<b> Atividade </b>\n",
        " \n",
        "23) Aplique este mÃ©todo nas revisÃµes ```texto_pos``` e ```texto_neg```.\n",
        "Para aplicar:\n",
        "\n",
        "```python\n",
        "sentence=TextBlob(texto)\n",
        "sentence.sentiment\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9IvBg5sZZpE"
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-BV6UkOZZpJ",
        "outputId": "5df5a4d1-e23e-4c15-9642-a7b0456c50b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence=TextBlob(texto_neg)\n",
        "sentence.sentiment"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.06385964912280702, subjectivity=0.5629824561403508)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1HyveDUt9Cz",
        "outputId": "384e9cb8-84bd-46d6-e0d9-7171215f5a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence=TextBlob(texto_pos)\n",
        "sentence.sentiment"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.190819118692253, subjectivity=0.6026226012793177)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwk7dHuFZZpO"
      },
      "source": [
        "## Afinn\n",
        "\n",
        "- Valor maior que 0 indica sentimento positivo\n",
        "- Valor menor que 0 indica sentimento negativo\n",
        "\n",
        "<b> Atividade </b>\n",
        "\n",
        "24) Aplique este mÃ©todo nas revisÃµes ```texto_pos``` e ```texto_neg```.\n",
        "Para aplicar:\n",
        "\n",
        "```python\n",
        "afinn = Afinn()\n",
        "afinn.score(texto)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2FS5AUsZZpP"
      },
      "source": [
        "from afinn import Afinn"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF8E0CjzZZpX"
      },
      "source": [
        "afinn = Afinn()"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFeaPAlluCUu",
        "outputId": "b396a80d-0798-4762-92a0-5adf743eb5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "afinn.score(texto_neg)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywP43scVuDqv",
        "outputId": "18ea5246-4b98-49df-9522-87cdd12a3459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "afinn.score(texto_pos)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhkDVIxZZpa"
      },
      "source": [
        "<b> Atividade </b>\n",
        "\n",
        "25) Para vocÃª, qual ferramenta teve melhor comportamento?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SWQvthbuG3T"
      },
      "source": [
        "Ao compararmos os trÃªs tipos de analises de sentimentos, podemos ver que o Vader possui um score mais detalhado de sentimentos positivos, negativos e neutros, por considerar cada sentenÃ§a do conjunto de palavras e categoriza elas de acordo com o sentimento. \n",
        "JÃ¡ o TextBlob trabalha com uma analise mais subjetiva, onde a interpretaÃ§Ã£o de cada sentenÃ§a deve ser um pouco mais precisa para poder ter uma maior acertiva, por ser uma metodologia baseada em polaridade e subjetividade. Por fim temos o Afinn, Ã© uma abodagem mais direta, onde tem uma biblioteca com um dicionario de palavras e sua classificaÃ§Ã£o como neutra, negativa ou positiva, este modelo nÃ£o consegue cobrir textos com uma variÃ§Ã£o grande de palavras, que claro nÃ£o estejam presentes em seu dicionÃ¡rio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWImUeS0ZZpb"
      },
      "source": [
        "# Dica:\n",
        "## Quando for trabalhar com um dataset em inglÃªs, a biblioteca Spacy facilita!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONqxhviZZpc",
        "outputId": "d9e23049-4ffe-474f-e5b8-b339f338c53f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96.4MB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.2.0)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-cp36-none-any.whl size=98051305 sha256=711061e6d2f63f990bb29ed12d213abf9b63c6862d30ad9de402a582b1a39860\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-be5otrmw/wheels/df/94/ad/f5cf59224cea6b5686ac4fd1ad19c8a07bc026e13c36502d81\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hj3KE97ZZph"
      },
      "source": [
        "import spacy\n",
        "import pandas as pd"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW0GLnhVZZpn"
      },
      "source": [
        "O scpay forne um pacote que jÃ¡ tem sÃ©rie de modelos jÃ¡ treinados em NLP. Inclusive para os embeddings em inglÃªs.\n",
        "\n",
        "Para mais informaÃ§Ãµes vÃ¡ em:\n",
        "\n",
        "https://spacy.io/models/en#en_core_web_md\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v02Lid1QZZpo"
      },
      "source": [
        "Com o mÃ©todo abaixo carregamos um dos modelos do spacy:\n",
        "\n",
        "```python\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "```\n",
        "\n",
        "Para aplicar o modelo, basta passar o texto para o modelo carregado anteriormente:\n",
        "\n",
        "```python\n",
        "doc = nlp(\"This is some text that I am processing with Spacy\")\n",
        "```\n",
        "\n",
        "Carregue o modelo e imprima doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjRx4bZxZZpo",
        "outputId": "f7b0f112-a36b-4644-f48a-698dc1b0dfed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "nlp = spacy.load('en_core_web_md')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-614d6de0ab0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_md'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDsD2THwZZps",
        "outputId": "670f4c93-5414-46ae-b3af-03c4ef5aa70a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "doc = nlp(\"This is some text that I am processing with Spacy\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-28dde4cb9d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This is some text that I am processing with Spacy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDWkp1tfZZpy"
      },
      "source": [
        "doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuqCJaIMZZp3"
      },
      "source": [
        "Ao aplicar o modelo carregado a variÃ¡vel <b> doc </b> jÃ¡ possui os embeddings de cada uma das palavras e o embedding da frase, que Ã© a mÃ©dia de todos vetores de todas palavras.\n",
        "\n",
        "```python\n",
        "#vetor da primeira palavra\n",
        "doc[0].vector\n",
        "#vetor agregado pela mÃ©dia - embedding do documento\n",
        "doc.vector\n",
        "```\n",
        "O cÃ³digo abaixo mostra que a mÃ©dia de uma posiÃ§Ã£o em especÃ­fico dos embeddings de todas as palavras e a posiÃ§Ã£o do embedding do documento possuem o mesmo valor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r426C5mvZZp4"
      },
      "source": [
        "def calcula_media_posicao(x):\n",
        "    soma = 0\n",
        "    vector = []\n",
        "    for i in range(0,len(doc)):\n",
        "        vector.append(doc[i].vector)    \n",
        "    \n",
        "    for v in vector:\n",
        "        soma += v[x]\n",
        "    return soma/len(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "969rVBBYZZp8"
      },
      "source": [
        "round(calcula_media_posicao(10),6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmkeEtyQZZqB"
      },
      "source": [
        "round(doc.vector[10], 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjZQ_jAMZZqF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}